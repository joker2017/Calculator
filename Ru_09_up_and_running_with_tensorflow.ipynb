{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ru_09_up_and_running_with_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "H71EDcraOY-4"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joker2017/Calculator/blob/master/Ru_09_up_and_running_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6J9dMJ6NOY-E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Chapter 9 – Up and running with TensorFlow**"
      ]
    },
    {
      "metadata": {
        "id": "nqwR6qFjOY-G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "_This notebook contains all the sample code and solutions to the exercises in chapter 9._"
      ]
    },
    {
      "metadata": {
        "id": "U163-3m2OY-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ]
    },
    {
      "metadata": {
        "id": "udu0ofQzOY-I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
      ]
    },
    {
      "metadata": {
        "id": "XtmNZqUpOY-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"tensorflow\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3oweKgMtOY-I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating and running a graph\n",
        "Создание и запуск графа"
      ]
    },
    {
      "metadata": {
        "id": "JJRYb9T1OY-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "x = tf.Variable(3, name=\"x\")\n",
        "y = tf.Variable(4, name=\"y\")\n",
        "f = x*x*y + y + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lzfLNL-ZOY-I",
        "colab_type": "code",
        "outputId": "2d38a88e-f87e-499f-beb8-be8b71d573c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "f"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "t0HUmH5LOY-Y",
        "colab_type": "code",
        "outputId": "f92a1959-af8c-4c49-da93-5007b0462b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(x.initializer)\n",
        "sess.run(y.initializer)\n",
        "result = sess.run(f)\n",
        "print(result)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yy40gP4nOY-Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GH1zAdylOY-Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    x.initializer.run()\n",
        "    y.initializer.run()\n",
        "    result = f.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hxuTVLlXOY-Y",
        "colab_type": "code",
        "outputId": "45afde51-9c45-4280-b8b8-343052145c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "00hMdZKcOY-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    result = f.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5RaTaL4gOY-n",
        "colab_type": "code",
        "outputId": "2f520c58-8d71-4205-983e-13074ac0e023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "iE5_eoicOY-n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hpS8ugXNOY-4",
        "colab_type": "code",
        "outputId": "e8320808-89d0-4b7e-e581-1dff4b39273a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sess = tf.InteractiveSession()\n",
        "init.run()\n",
        "result = f.eval()\n",
        "print(result)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Unko_LmaOY-4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q9gbHm2hOY-4",
        "colab_type": "code",
        "outputId": "e1250b8c-fd8e-4304-bd5c-4dd681f0b213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "H71EDcraOY-4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Managing graphs"
      ]
    },
    {
      "metadata": {
        "id": "sqwMQ3nkOY_H",
        "colab_type": "code",
        "outputId": "d37b1360-62a5-4360-d20d-2730651e79aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "x1 = tf.Variable(1)\n",
        "x1.graph is tf.get_default_graph()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "pmbV8z4ZOY_H",
        "colab_type": "code",
        "outputId": "f6578b59-bc37-4ec0-ae56-c3e0eedca75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    x2 = tf.Variable(2)\n",
        "\n",
        "x2.graph is graph"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "5OfOiDnqOY_H",
        "colab_type": "code",
        "outputId": "e9d7a889-d251-4922-d5eb-5e27c7b5b0be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x2.graph is tf.get_default_graph()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "QYx6jJjuOY_H",
        "colab_type": "code",
        "outputId": "28a9fa81-52ba-4ae1-bc5e-c6fc74eb1b27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "w = tf.constant(3)\n",
        "x = w + 2\n",
        "y = x + 5\n",
        "z = x * 3\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(y.eval())  # 10\n",
        "    print(z.eval())  # 15"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oAQx5r3ROY_W",
        "colab_type": "code",
        "outputId": "4e9c0cd4-197c-4731-c53e-f10c7c8c9669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    y_val, z_val = sess.run([y, z])\n",
        "    print(y_val)  # 10\n",
        "    print(z_val)  # 15"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-R2tSQ9gOY_W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "metadata": {
        "id": "oTosTmhqOY_W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Используем нормальное распределение\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "mtcHJoGCOY_W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "#reset_graph()\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
        "\n",
        "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "XT = tf.transpose(X)\n",
        "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    theta_value = theta.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GFufkC1ZOY_W",
        "colab_type": "code",
        "outputId": "bc57710a-d6e5-4dad-f893-810183fe6fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "theta_value"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.7112991e+01],\n",
              "       [ 4.3611991e-01],\n",
              "       [ 9.4082914e-03],\n",
              "       [-1.0654381e-01],\n",
              "       [ 6.4201808e-01],\n",
              "       [-4.0360574e-06],\n",
              "       [-3.7822633e-03],\n",
              "       [-4.2303962e-01],\n",
              "       [-4.3648642e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "Ig_ITnFEOY_m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сравните с чистым NumPy"
      ]
    },
    {
      "metadata": {
        "id": "OF7Sr0zuOY_m",
        "colab_type": "code",
        "outputId": "bcd6aaf7-9736-454b-8590-18b567012922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "X = housing_data_plus_bias\n",
        "y = housing.target.reshape(-1, 1)\n",
        "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
        "\n",
        "print(theta_numpy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-3.69419202e+01]\n",
            " [ 4.36693293e-01]\n",
            " [ 9.43577803e-03]\n",
            " [-1.07322041e-01]\n",
            " [ 6.45065694e-01]\n",
            " [-3.97638942e-06]\n",
            " [-3.78654265e-03]\n",
            " [-4.21314378e-01]\n",
            " [-4.34513755e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZY7hxTtOOY_m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compare with Scikit-Learn \n",
        "\n",
        "Сравнить с Scikit-Learn"
      ]
    },
    {
      "metadata": {
        "id": "aQOZwMY5OY_m",
        "colab_type": "code",
        "outputId": "d84967fb-f90e-44fa-b3df-40aa8b3ed436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing.data, housing.target.reshape(-1, 1))\n",
        "\n",
        "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-3.69419202e+01]\n",
            " [ 4.36693293e-01]\n",
            " [ 9.43577803e-03]\n",
            " [-1.07322041e-01]\n",
            " [ 6.45065694e-01]\n",
            " [-3.97638942e-06]\n",
            " [-3.78654265e-03]\n",
            " [-4.21314378e-01]\n",
            " [-4.34513755e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OBfAWPIOOY_m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using Batch Gradient Descent / Используем градиентный спуск\n"
      ]
    },
    {
      "metadata": {
        "id": "FZB-kSgBOY_m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Gradient Descent requires scaling the feature vectors first. We could do this using TF, but let's just use Scikit-Learn for now. \n",
        "\n",
        "Градиентный спуск требует масштабирования векторов признаков. Мы могли бы сделать это с помощью TF, но давайте просто использовать Scikit-Learn на данный момент."
      ]
    },
    {
      "metadata": {
        "id": "0z7YRfgvOY_m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_housing_data = scaler.fit_transform(housing.data)\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qFFDQLoCOY_m",
        "colab_type": "code",
        "outputId": "96ff4043-1256-45b0-c901-f61609b0d6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "cell_type": "code",
      "source": [
        "print(scaled_housing_data_plus_bias.mean(axis=0))\n",
        "print(scaled_housing_data_plus_bias.mean(axis=1))\n",
        "print(scaled_housing_data_plus_bias.mean())\n",
        "print(scaled_housing_data_plus_bias.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.00000000e+00  6.60969987e-17  5.50808322e-18  6.60969987e-17\n",
            " -1.06030602e-16 -1.10161664e-17  3.44255201e-18 -1.07958431e-15\n",
            " -8.52651283e-15]\n",
            "[ 0.38915536  0.36424355  0.5116157  ... -0.06612179 -0.06360587\n",
            "  0.01359031]\n",
            "0.11111111111111005\n",
            "(20640, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ztz5nkk9OY_1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Manually computing the gradients \n",
        " \n",
        " Ручное вычисление градиентов"
      ]
    },
    {
      "metadata": {
        "id": "my-Asa9rOY_1",
        "colab_type": "code",
        "outputId": "153ad370-0fa9-452d-8837-05411a940395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "#reset_graph()\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_housing_data = scaler.fit_transform(housing.data)\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\") # генерировать случайный тензер с заданой формой и диапазоном\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
        "training_op = tf.assign(theta, theta - learning_rate * gradients) # создает узел который будет присваивать переменной новое значение (шаг пакетного градиентного спуска)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 9.161543\n",
            "Epoch 100 MSE = 0.71450067\n",
            "Epoch 200 MSE = 0.5667049\n",
            "Epoch 300 MSE = 0.5555718\n",
            "Epoch 400 MSE = 0.5488112\n",
            "Epoch 500 MSE = 0.5436362\n",
            "Epoch 600 MSE = 0.5396294\n",
            "Epoch 700 MSE = 0.5365092\n",
            "Epoch 800 MSE = 0.5340678\n",
            "Epoch 900 MSE = 0.5321474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LL7yPgFVOY_1",
        "colab_type": "code",
        "outputId": "4320581b-809c-4f94-87dd-2e1c1b648b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "best_theta"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.0685523 ],\n",
              "       [ 0.8874027 ],\n",
              "       [ 0.14401656],\n",
              "       [-0.3477088 ],\n",
              "       [ 0.36178362],\n",
              "       [ 0.00393811],\n",
              "       [-0.04269556],\n",
              "       [-0.66145283],\n",
              "       [-0.6375278 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "qfv9k0PROZAF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using autodiff"
      ]
    },
    {
      "metadata": {
        "id": "mNi2a24bOZAF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Same as above except for the `gradients = ...` line:    \n",
        "\n",
        "То же, что и выше, за исключением градиентов = ... строка:\n"
      ]
    },
    {
      "metadata": {
        "id": "LqGVuyjJOZAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OLiXR2PWOZAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gradients = tf.gradients(mse, [theta])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXWVYziSOZAF",
        "colab_type": "code",
        "outputId": "55a18225-5f07-4ad6-fc2c-f08f5da2ee1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "cell_type": "code",
      "source": [
        "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "\n",
        "print(\"Best theta:\")\n",
        "print(best_theta)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 9.161543\n",
            "Epoch 100 MSE = 0.7145006\n",
            "Epoch 200 MSE = 0.566705\n",
            "Epoch 300 MSE = 0.5555718\n",
            "Epoch 400 MSE = 0.54881126\n",
            "Epoch 500 MSE = 0.54363626\n",
            "Epoch 600 MSE = 0.5396294\n",
            "Epoch 700 MSE = 0.5365092\n",
            "Epoch 800 MSE = 0.5340678\n",
            "Epoch 900 MSE = 0.5321474\n",
            "Best theta:\n",
            "[[ 2.0685525 ]\n",
            " [ 0.8874027 ]\n",
            " [ 0.14401658]\n",
            " [-0.34770882]\n",
            " [ 0.36178368]\n",
            " [ 0.00393811]\n",
            " [-0.04269556]\n",
            " [-0.6614528 ]\n",
            " [-0.6375277 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5_71OmR5OZAF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How could you find the partial derivatives of the following function with regards to `a` and `b`?\n",
        "\n",
        "Как вы можете найти частные производные от следующей функции относительно a и b?"
      ]
    },
    {
      "metadata": {
        "id": "K5QeYmvlOZAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_func(a, b):\n",
        "    z = 0\n",
        "    for i in range(100):\n",
        "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xs-9G47pOZAF",
        "colab_type": "code",
        "outputId": "be6dc8bb-c73b-478f-8d55-9d5993ecd652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "my_func(0.2, 0.3)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.21253923284754914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "Eh--Oad_OZAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "a = tf.Variable(0.2, name=\"a\")\n",
        "b = tf.Variable(0.3, name=\"b\")\n",
        "z = tf.constant(0.0, name=\"z0\")\n",
        "for i in range(100):\n",
        "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
        "\n",
        "grads = tf.gradients(z, [a, b])\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c58Yz-MHOZAV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's compute the function at $a=0.2$ and $b=0.3$, and the partial derivatives at that point with regards to $a$ and with regards to $b$:\n",
        "\n",
        "Вычислим функцию при a = 0.2 и b = 0.3 и частные производные в этой точке относительно a и относительно b:"
      ]
    },
    {
      "metadata": {
        "id": "J5ji1T-ZOZAV",
        "colab_type": "code",
        "outputId": "dfaf6362-004c-4871-c15d-463208522bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    print(z.eval())\n",
        "    print(sess.run(grads))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.21253741\n",
            "[-1.1388494, 0.19671395]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xVAQj54YOZAV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using a `GradientDescentOptimizer`"
      ]
    },
    {
      "metadata": {
        "id": "ExxeKoTAOZAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6NgAmvEvOZAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p82jgEA_OZAk",
        "colab_type": "code",
        "outputId": "73e2886b-309b-42a3-d304-7ebaa197bf73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "\n",
        "print(\"Best theta:\")\n",
        "print(best_theta)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 MSE = 9.161543\n",
            "Epoch 100 MSE = 0.7145007\n",
            "Epoch 200 MSE = 0.566705\n",
            "Epoch 300 MSE = 0.5555718\n",
            "Epoch 400 MSE = 0.5488112\n",
            "Epoch 500 MSE = 0.5436362\n",
            "Epoch 600 MSE = 0.5396294\n",
            "Epoch 700 MSE = 0.5365092\n",
            "Epoch 800 MSE = 0.5340678\n",
            "Epoch 900 MSE = 0.5321474\n",
            "Best theta:\n",
            "[[ 2.0685523 ]\n",
            " [ 0.88740265]\n",
            " [ 0.14401655]\n",
            " [-0.34770873]\n",
            " [ 0.3617836 ]\n",
            " [ 0.00393811]\n",
            " [-0.04269556]\n",
            " [-0.6614529 ]\n",
            " [-0.6375279 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1lAAeaUvOZAk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using a momentum optimizer"
      ]
    },
    {
      "metadata": {
        "id": "23TcVUDqOZAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3KCwD4SOZA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
        "                                       momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d2EdjRvUOZA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BL61z-UYOZA0",
        "colab_type": "code",
        "outputId": "d861f0cd-bf64-4b5c-f91a-90b3fbfb6a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "\n",
        "print(\"Best theta:\")\n",
        "print(best_theta)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best theta:\n",
            "[[ 2.068558  ]\n",
            " [ 0.8296286 ]\n",
            " [ 0.11875336]\n",
            " [-0.26554462]\n",
            " [ 0.305711  ]\n",
            " [-0.00450251]\n",
            " [-0.03932662]\n",
            " [-0.8998644 ]\n",
            " [-0.87052065]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7zTooYyfOZA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Feeding data to the training algorithm\n",
        "\n",
        " Подача данных в алгоритм обучения"
      ]
    },
    {
      "metadata": {
        "id": "5i_XjhN3OZA0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Placeholder nodes\n",
        "\n",
        "Узлы-заполнитель"
      ]
    },
    {
      "metadata": {
        "id": "T7vN4ND9OZA0",
        "colab_type": "code",
        "outputId": "ae9f5bbd-dc18-4aa6-8273-aa83dbfc9729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
        "B = A + 5\n",
        "with tf.Session() as sess:\n",
        "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
        "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
        "\n",
        "print(B_val_1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[6. 7. 8.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N0bNzudfOZBE",
        "colab_type": "code",
        "outputId": "84b5867b-b478-4191-9876-5a7ec1548a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(B_val_2)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 9. 10. 11.]\n",
            " [12. 13. 14.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tnr-zzapOZBE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mini-batch Gradient Descent\n",
        "\n",
        "Мини-пакетный градиентный спуск"
      ]
    },
    {
      "metadata": {
        "id": "pZgfeo4cOZBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBDhBeTkOZBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfvueAG-OZBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TbG3TzbnOZBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tvlZH6GhOZBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "n_batches = int(np.ceil(m / batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jup0a-lFOZBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fetch_batch(epoch, batch_index, batch_size):\n",
        "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
        "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
        "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
        "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
        "    return X_batch, y_batch\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "      \n",
        "      for batch_index in range(n_batches):\n",
        "            if epoch % 100 == 0:\n",
        "               print(\"Epoch\", epoch)\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            print(X_batch, y_batch)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "   #   best_theta = theta.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cC8OHD1HOZBT",
        "colab_type": "code",
        "outputId": "974a9f9c-4f52-4cc5-b5a7-598a5379bbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        "best_theta"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.0703337 ],\n",
              "       [ 0.8637145 ],\n",
              "       [ 0.12255149],\n",
              "       [-0.31211886],\n",
              "       [ 0.38510385],\n",
              "       [ 0.00434167],\n",
              "       [-0.01232954],\n",
              "       [-0.83376896],\n",
              "       [-0.8030471 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "hni2FfzYOZBT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Saving and restoring a model"
      ]
    },
    {
      "metadata": {
        "id": "O8mpu4CfOZBT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "n_epochs = 1000                                                                       # not shown in the book\n",
        "learning_rate = 0.01                                                                  # not shown\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")            # not shown\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")            # not shown\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")                                      # not shown\n",
        "error = y_pred - y                                                                    # not shown\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")                                    # not shown\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)            # not shown\n",
        "training_op = optimizer.minimize(mse)                                                 # not shown\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())                                # not shown\n",
        "            save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()\n",
        "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-1jRp7ZOZBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7h9bqPWYOZBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
        "    best_theta_restored = theta.eval() # not shown in the book"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lxRdgREoOZBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.allclose(best_theta, best_theta_restored)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0N0OEUjOZBj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you want to have a saver that loads and restores `theta` with a different name, such as `\"weights\"`:\n",
        "\n",
        "Если вы хотите иметь заставку, которая загружает и восстанавливает `theta` с другим именем, например «вес»"
      ]
    },
    {
      "metadata": {
        "id": "HPjoQxvIOZBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver({\"weights\": theta})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MyiN1h0wOZBj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "By default the saver also saves the graph structure itself in a second file with the extension `.meta`. You can use the function `tf.train.import_meta_graph()` to restore the graph structure. This function loads the graph into the default graph and returns a `Saver` that can then be used to restore the graph state (i.e., the variable values):\n",
        "\n",
        "По умолчанию saver также сохраняет структуру графа во втором файле с расширением .meta. Вы можете использовать функцию `tf.train.import_meta_graph()` для восстановления структуры графа. Эта функция загружает граф в граф по умолчанию и возвращает Saver, который затем может быть использован для восстановления состояния графа (т. е. Значений переменных):"
      ]
    },
    {
      "metadata": {
        "id": "Rgz3D6K-OZBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "# notice that we start with an empty graph.\n",
        "\n",
        "saver = tf.train.import_meta_graph(\"/tmp/my_model_final.ckpt.meta\")  # this loads the graph structure\n",
        "theta = tf.get_default_graph().get_tensor_by_name(\"theta:0\") # not shown in the book\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")  # this restores the graph's state\n",
        "    best_theta_restored = theta.eval() # not shown in the book"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9N4QcpS4OZBy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.allclose(best_theta, best_theta_restored)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vDvZNjF1OZBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This means that you can import a pretrained model without having to have the corresponding Python code to build the graph. This is very handy when you keep tweaking and saving your model: you can load a previously saved model without having to search for the version of the code that built it.\n",
        "\n",
        "Это означает, что вы можете импортировать предварительно обработанную модель без необходимости иметь соответствующий код Python для построения графа. Это очень удобно, когда вы продолжаете настраивать и сохранять свою модель: вы можете загрузить ранее сохраненную модель без необходимости поиска версии кода, которая ее построила."
      ]
    },
    {
      "metadata": {
        "id": "SnUS4_2iOZBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualizing the graph\n",
        "## inside Jupyter"
      ]
    },
    {
      "metadata": {
        "id": "EhWbrPmyOZBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To visualize the graph within Jupyter, we will use a TensorBoard server available online at https://tensorboard.appspot.com/ (so this will not work if you do not have Internet access).  As far as I can tell, this code was originally written by Alex Mordvintsev in his [DeepDream tutorial](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb). Alternatively, you could use a tool like [tfgraphviz](https://github.com/akimach/tfgraphviz)."
      ]
    },
    {
      "metadata": {
        "id": "NZWZMwu7OZBy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from tensorflow_graph_in_jupyter import show_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNcaYTGbOZBy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGbfx_yrOZBy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using TensorBoard"
      ]
    },
    {
      "metadata": {
        "id": "LPhsa5zwOZBy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Добавляем в начало программы:\n",
        "reset_graph()\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "root_logdir = \"tf_logs\"\n",
        "logdir = \"{}/run-{}/\".format(root_logdir, now)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gAN8eROyOZCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F75Ar4AIOZCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Добавляем в самый конец стадии построения\n",
        "\n",
        "mse_summary = tf.summary.scalar('MSE', mse)  # создает в графе узел который будет подсчитывать  MSE и записывать его в строку журнала TenserBoard двоичного журнала назыв summary\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph()) # создает обьект который будет применяться для записи summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z7WR9KcuOZCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "batch_size = 100\n",
        "n_batches = int(np.ceil(m / batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vnuSAsyZOZCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:                                                        # not shown in the book\n",
        "    sess.run(init)                                                                # not shown\n",
        "\n",
        "    for epoch in range(n_epochs):                                                 # not shown\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            if batch_index % 10 == 0:\n",
        "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "                step = epoch * n_batches + batch_index\n",
        "                file_writer.add_summary(summary_str, step)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "    best_theta = theta.eval()                                                     # not shown"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RirvYBdvOZCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Закрываем запись журнала\n",
        "\n",
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5URctR7yOZCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XSepzmtNOZCC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Name scopes"
      ]
    },
    {
      "metadata": {
        "id": "RC5jn0oUOZCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "root_logdir = \"tf_logs\"\n",
        "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
        "\n",
        "n_epochs = 1000\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sFYrnOG-OZCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"loss\") as scope:                                      # так добавляется пространство имен\n",
        "    error = y_pred - y\n",
        "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dhFe2IHJOZCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "mse_summary = tf.summary.scalar('MSE', mse)\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "04uofMmmOZCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "batch_size = 100\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
        "            if batch_index % 10 == 0:\n",
        "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "                step = epoch * n_batches + batch_index\n",
        "                file_writer.add_summary(summary_str, step)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "\n",
        "    best_theta = theta.eval()\n",
        "\n",
        "file_writer.flush()\n",
        "file_writer.close()\n",
        "print(\"Best theta:\")\n",
        "print(best_theta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YaW-r7KKOZCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(error.op.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXGAxamIOZCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(mse.op.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fXOI86rmOZCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "a1 = tf.Variable(0, name=\"a\")      # name == \"a\"\n",
        "a2 = tf.Variable(0, name=\"a\")      # name == \"a_1\"\n",
        "\n",
        "with tf.name_scope(\"param\"):       # name == \"param\"\n",
        "    a3 = tf.Variable(0, name=\"a\")  # name == \"param/a\"\n",
        "\n",
        "with tf.name_scope(\"param\"):       # name == \"param_1\"\n",
        "    a4 = tf.Variable(0, name=\"a\")  # name == \"param_1/a\"\n",
        "\n",
        "for node in (a1, a2, a3, a4):\n",
        "    print(node.op.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GWyz7NlaOZCS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modularity"
      ]
    },
    {
      "metadata": {
        "id": "sy8AR9RZOZCS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ugly flat code:\n",
        " \n",
        " уродливый плоский код:"
      ]
    },
    {
      "metadata": {
        "id": "DUMPXsjxOZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
        "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
        "b1 = tf.Variable(0.0, name=\"bias1\")\n",
        "b2 = tf.Variable(0.0, name=\"bias2\")\n",
        "\n",
        "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
        "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
        "\n",
        "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
        "relu2 = tf.maximum(z1, 0., name=\"relu2\")  # Oops, cut&paste error! Did you spot it?\n",
        "\n",
        "output = tf.add(relu1, relu2, name=\"output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNWg0Mb2OZCh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Much better, using a function to build the ReLUs:\n",
        "\n",
        "Гораздо лучше, используя функцию для создания ReLU:"
      ]
    },
    {
      "metadata": {
        "id": "iIkLIZA0OZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    w_shape = (int(X.get_shape()[1]), 1)\n",
        "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
        "    b = tf.Variable(0.0, name=\"bias\")\n",
        "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
        "    return tf.maximum(z, 0., name=\"relu\")\n",
        "\n",
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXYGt1BAOZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_writer = tf.summary.FileWriter(\"logs/relu1\", tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HFriMCv5OZCh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Even better using name scopes:\n",
        "\n",
        "Еще лучше использовать области имен:"
      ]
    },
    {
      "metadata": {
        "id": "Vm7KKrTuOZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    with tf.name_scope(\"relu\"):\n",
        "        w_shape = (int(X.get_shape()[1]), 1)                          # not shown in the book\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")    # not shown\n",
        "        b = tf.Variable(0.0, name=\"bias\")                             # not shown\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                      # not shown\n",
        "        return tf.maximum(z, 0., name=\"max\")                          # not shown"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "McOxVwULOZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_features = 3\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")\n",
        "\n",
        "file_writer = tf.summary.FileWriter(\"logs/relu2\", tf.get_default_graph())\n",
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HNGxUUErOZCh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sharing Variables\n",
        "Совместное использование переменных"
      ]
    },
    {
      "metadata": {
        "id": "1fiROFk8OZCh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sharing a `threshold` variable the classic way, by defining it outside of the `relu()` function then passing it as a parameter:\n",
        "\n",
        "Разделяя пороговую переменную классическим способом, определяя ее вне функции relu (), передавая ее как параметр:"
      ]
    },
    {
      "metadata": {
        "id": "BPDg7qixOZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X, threshold):\n",
        "    with tf.name_scope(\"relu\"):\n",
        "        w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
        "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown не понятно\n",
        "        return tf.maximum(z, threshold, name=\"max\")\n",
        "\n",
        "threshold = tf.Variable(0.0, name=\"threshold\")\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X, threshold) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OjogVc6-OZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    with tf.name_scope(\"relu\"):\n",
        "        if not hasattr(relu, \"threshold\"):\n",
        "            relu.threshold = tf.Variable(0.0, name=\"threshold\")\n",
        "        w_shape = int(X.get_shape()[1]), 1                          # not shown in the book\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
        "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
        "        return tf.maximum(z, relu.threshold, name=\"max\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "10aauK8jOZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = [relu(X) for i in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VwkG1jHQOZCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "with tf.variable_scope(\"relu\"):\n",
        "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
        "                                initializer=tf.constant_initializer(0.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4j6VtLpcOZCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"relu\", reuse=True):\n",
        "    threshold = tf.get_variable(\"threshold\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ob0ZaWj2OZCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"relu\") as scope:\n",
        "    scope.reuse_variables()\n",
        "    threshold = tf.get_variable(\"threshold\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A7eW_OXoOZCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    with tf.variable_scope(\"relu\", reuse=True):\n",
        "        threshold = tf.get_variable(\"threshold\")\n",
        "        w_shape = int(X.get_shape()[1]), 1                          # not shown\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
        "        b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
        "        return tf.maximum(z, threshold, name=\"max\")\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "with tf.variable_scope(\"relu\"):\n",
        "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
        "                                initializer=tf.constant_initializer(0.0))\n",
        "relus = [relu(X) for relu_index in range(5)]\n",
        "output = tf.add_n(relus, name=\"output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VUxTxZ4GOZCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_writer = tf.summary.FileWriter(\"logs/relu6\", tf.get_default_graph())\n",
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L9MW0jLwOZCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    with tf.variable_scope(\"relu\"):\n",
        "        threshold = tf.get_variable(\"threshold\", shape=(), initializer=tf.constant_initializer(0.0))\n",
        "        w_shape = (int(X.get_shape()[1]), 1)\n",
        "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
        "        b = tf.Variable(0.0, name=\"bias\")\n",
        "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
        "        return tf.maximum(z, threshold, name=\"max\")\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "with tf.variable_scope(\"\", default_name=\"\") as scope:\n",
        "    first_relu = relu(X)     # create the shared variable\n",
        "    scope.reuse_variables()  # then reuse it\n",
        "    relus = [first_relu] + [relu(X) for i in range(4)]\n",
        "output = tf.add_n(relus, name=\"output\")\n",
        "\n",
        "file_writer = tf.summary.FileWriter(\"logs/relu8\", tf.get_default_graph())\n",
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0qgo8xnNOZCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "def relu(X):\n",
        "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
        "                                initializer=tf.constant_initializer(0.0))\n",
        "    w_shape = (int(X.get_shape()[1]), 1)                        # not shown in the book\n",
        "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")  # not shown\n",
        "    b = tf.Variable(0.0, name=\"bias\")                           # not shown\n",
        "    z = tf.add(tf.matmul(X, w), b, name=\"z\")                    # not shown\n",
        "    return tf.maximum(z, threshold, name=\"max\")\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
        "relus = []\n",
        "for relu_index in range(5):\n",
        "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
        "        relus.append(relu(X))\n",
        "output = tf.add_n(relus, name=\"output\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "poiytgnTOZCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_writer = tf.summary.FileWriter(\"logs/relu9\", tf.get_default_graph())\n",
        "file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5yXsoANcOZCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Extra material\n",
        "\n",
        "Дополнительный материал"
      ]
    },
    {
      "metadata": {
        "id": "2afsQTwSOZCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "with tf.variable_scope(\"my_scope\"):\n",
        "    x0 = tf.get_variable(\"x\", shape=(), initializer=tf.constant_initializer(0.))\n",
        "    x1 = tf.Variable(0., name=\"x\")\n",
        "    x2 = tf.Variable(0., name=\"x\")\n",
        "\n",
        "with tf.variable_scope(\"my_scope\", reuse=True):\n",
        "    x3 = tf.get_variable(\"x\")\n",
        "    x4 = tf.Variable(0., name=\"x\")\n",
        "\n",
        "with tf.variable_scope(\"\", default_name=\"\", reuse=True):\n",
        "    x5 = tf.get_variable(\"my_scope/x\")\n",
        "\n",
        "print(\"x0:\", x0.op.name)\n",
        "print(\"x1:\", x1.op.name)\n",
        "print(\"x2:\", x2.op.name)\n",
        "print(\"x3:\", x3.op.name)\n",
        "print(\"x4:\", x4.op.name)\n",
        "print(\"x5:\", x5.op.name)\n",
        "print(x0 is x3 and x3 is x5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHzS853-OZCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first `variable_scope()` block first creates the shared variable `x0`, named `my_scope/x`. For all operations other than shared variables (including non-shared variables), the variable scope acts like a regular name scope, which is why the two variables `x1` and `x2` have a name with a prefix `my_scope/`. Note however that TensorFlow makes their names unique by adding an index: `my_scope/x_1` and `my_scope/x_2`.\n",
        "\n",
        "The second `variable_scope()` block reuses the shared variables in scope `my_scope`, which is why `x0 is x3`. Once again, for all operations other than shared variables it acts as a named scope, and since it's a separate block from the first one, the name of the scope is made unique by TensorFlow (`my_scope_1`) and thus the variable `x4` is named `my_scope_1/x`.\n",
        "\n",
        "The third block shows another way to get a handle on the shared variable `my_scope/x` by creating a `variable_scope()` at the root scope (whose name is an empty string), then calling `get_variable()` with the full name of the shared variable (i.e. `\"my_scope/x\"`).\n",
        "\n",
        "\n",
        "Первый блок variable_scope() сначала создает общую переменную x0 с именем my_scope/x. Для всех операций, отличных от общих переменных (включая не общие переменные), область переменных действует как регулярная область имен, поэтому две переменные x1 и x2 имеют имя с префиксом my_scope/. Обратите внимание, однако, что TensorFlow делает их имена уникальными, добавляя индекс: my_scope/ x_1 и my_scope /x_2.\n",
        "\n",
        "Второй блок variable_scope() повторно использует общие переменные в области my_scope, поэтому x0 является x3. Еще раз, для всех операций, отличных от общих переменных, он действует как именованная область, и поскольку это отдельный блок из первого, имя области создается уникальным TensorFlow (my_scope_1), и поэтому переменная x4 называется my_scope_1/x.\n",
        "\n",
        "Третий блок показывает другой способ получить дескриптор общей переменной my_scope/x, создав variable_scope() в корневой области (имя которой является пустой строкой), а затем вызывает get_variable() с полным именем общей переменной ( т.е. «my_scope/x»).\n"
      ]
    },
    {
      "metadata": {
        "id": "OOqRzcsLOZCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Strings"
      ]
    },
    {
      "metadata": {
        "id": "nn_d1ddzOZDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "text = np.array(\"Do you want some café?\".split())\n",
        "text_tensor = tf.constant(text)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    print(text_tensor.eval())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pm5U0pouOZDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Autodiff"
      ]
    },
    {
      "metadata": {
        "id": "iGPNNq78OZDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: the autodiff content was moved to the [extra_autodiff.ipynb](extra_autodiff.ipynb) notebook."
      ]
    },
    {
      "metadata": {
        "id": "73L_-WU1OZDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercise solutions"
      ]
    },
    {
      "metadata": {
        "id": "X1EHmetvOZDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "See appendix A."
      ]
    },
    {
      "metadata": {
        "id": "AJJhuPVTOZDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 12. Logistic Regression with Mini-Batch Gradient Descent using TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "ceDZIFrFOZDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, let's create the moons dataset using Scikit-Learn's `make_moons()` function:\n",
        "\n",
        "Сначала давайте создадим набор данных \"moons\", используя функцию make_moons() Scikit-Learn:"
      ]
    },
    {
      "metadata": {
        "id": "rsMjFgxJOZDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "m = 1000\n",
        "X_moons, y_moons = make_moons(m, noise=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qQIhRouOZDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take a peek at the dataset:\n",
        "\n",
        "Давайте взглянем на набор данных:"
      ]
    },
    {
      "metadata": {
        "id": "pFyTOsfuOZDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "plt.plot(X_moons[y_moons == 1, 0], X_moons[y_moons == 1, 1], 'go', label=\"Positive\")\n",
        "plt.plot(X_moons[y_moons == 0, 0], X_moons[y_moons == 0, 1], 'r^', label=\"Negative\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6OG_PHTMOZDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We must not forget to add an extra bias feature ($x_0 = 1$) to every instance. For this, we just need to add a column full of 1s on the left of the input matrix $\\mathbf{X}$:\n",
        "\n",
        "Мы не должны забывать добавлять дополнительное смещение ($x_0 = 1$) к каждому экземпляру. Для этого нам просто нужно добавить столбец слева от входной матрицы $\\mathbf{X}$:"
      ]
    },
    {
      "metadata": {
        "id": "Lp4nqmVOOZDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_moons_with_bias = np.c_[np.ones((m, 1)), X_moons]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WjRLdyYPOZDB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's check:\n",
        "\n",
        "Давай проверим:"
      ]
    },
    {
      "metadata": {
        "id": "dTsfRqMvOZDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_moons_with_bias[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hz4ioz7OZDQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looks good. Now let's reshape `y_train` to make it a column vector (i.e. a 2D array with a single column):\n",
        "\n",
        "*Выглядит неплохо. Теперь давайте изменим y_train, чтобы сделать его вектором-столбцом (т.е. 2D-массив с одним столбцом):*"
      ]
    },
    {
      "metadata": {
        "id": "wPLtJCkZOZDQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_moons_column_vector = y_moons.reshape(-1, 1)\n",
        "y_moons_column_vector[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cYSOJbExOZDQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's split the data into a training set and a test set:\n",
        "\n",
        "*Теперь разделим данные на обучающий и тестовый наборы:*\n"
      ]
    },
    {
      "metadata": {
        "id": "zCHMuFYPOZDQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_ratio = 0.2\n",
        "test_size = int(m * test_ratio)\n",
        "X_train = X_moons_with_bias[:-test_size]\n",
        "X_test = X_moons_with_bias[-test_size:]\n",
        "y_train = y_moons_column_vector[:-test_size]\n",
        "y_test = y_moons_column_vector[-test_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CU0EiEKsOZDQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ok, now let's create a small function to generate training batches. In this implementation we will just pick random instances from the training set for each batch. This means that a single batch may contain the same instance multiple times, and also a single epoch may not cover all the training instances (in fact it will generally cover only about two thirds of the instances). However, in practice this is not an issue and it simplifies the code:\n",
        "\n",
        "*Хорошо, теперь давайте создадим небольшую функцию для создания учебных партий. В этой реализации мы просто выберем случайные экземпляры из набора тренировок для каждой партии. Это означает, что одна партия может содержать один и тот же экземпляр несколько раз, а также одна эпоха может не охватывать все учебные экземпляры (на самом деле она обычно охватывает только около двух третей экземпляров). Однако на практике это не проблема, и это упрощает код:*"
      ]
    },
    {
      "metadata": {
        "id": "4qf4VXfpOZDQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def random_batch(X_train, y_train, batch_size):\n",
        "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
        "    X_batch = X_train[rnd_indices]\n",
        "    y_batch = y_train[rnd_indices]\n",
        "    return X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "katQOlH2OZDQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's look at a small batch:\n",
        "\n",
        "*Давайте посмотрим на небольшую партию:*"
      ]
    },
    {
      "metadata": {
        "id": "enuedjkwOZDQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_batch, y_batch = random_batch(X_train, y_train, 5)\n",
        "X_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EWLXPkCnOZDQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KIizcZOkOZDQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Great! Now that the data is ready to be fed to the model, we need to build that model. Let's start with a simple implementation, then we will add all the bells and whistles.\n",
        "\n",
        "*Замечательно! Теперь, когда данные готовы к загрузке модели, нам нужно построить эту модель. Начнем с простой реализации, затем мы добавим украшения.*"
      ]
    },
    {
      "metadata": {
        "id": "MdQ71kXAOZDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First let's reset the default graph.\n",
        "\n",
        "*Сначала давайте сделаем граф по умолчанию.*"
      ]
    },
    {
      "metadata": {
        "id": "Rr4PFmNROZDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xEn6yq9OZDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The _moons_ dataset has two input features, since each instance is a point on a plane (i.e., 2-Dimensional):\n",
        "\n",
        "*Набор данных \"moons\" имеет две входные фичи, поскольку каждый экземпляр является точкой на плоскости (т.е. 2-мерной):*"
      ]
    },
    {
      "metadata": {
        "id": "pDLxEuVlOZDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_inputs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "69HInZi7OZDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's build the Logistic Regression model. As we saw in chapter 4, this model first computes a weighted sum of the inputs (just like the Linear Regression model), and then it applies the sigmoid function to the result, which gives us the estimated probability for the positive class:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*Теперь давайте построим модель логистической регрессии. Как мы видели в главе 4, эта модель сначала вычисляет взвешенную сумму входов (как и модель линейной регрессии), а затем применяет сигмоидную функцию к результату, что дает нам вероятностную оценку для положительного класса:*\n",
        "\n",
        "$\\hat{p} = h_\\boldsymbol{\\theta}(\\mathbf{x}) = \\sigma(\\boldsymbol{\\theta}^T \\mathbf{x})$\n"
      ]
    },
    {
      "metadata": {
        "id": "Dh4iae7ROZDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recall that $\\boldsymbol{\\theta}$ is the parameter vector, containing the bias term $\\theta_0$ and the weights $\\theta_1, \\theta_2, \\dots, \\theta_n$. The input vector $\\mathbf{x}$ contains a constant term $x_0 = 1$, as well as all the input features $x_1, x_2, \\dots, x_n$.\n",
        "\n",
        "Since we want to be able to make predictions for multiple instances at a time, we will use an input matrix $\\mathbf{X}$ rather than a single input vector. The $i^{th}$ row will contain the transpose of the $i^{th}$ input vector $(\\mathbf{x}^{(i)})^T$. It is then possible to estimate the probability that each instance belongs to the positive class using the following equation:\n",
        "\n",
        "$ \\hat{\\mathbf{p}} = \\sigma(\\mathbf{X} \\boldsymbol{\\theta})$\n",
        "\n",
        "That's all we need to build the model:\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*Напомним, что $\\boldsymbol{\\theta}$ - это вектор-параметр, содержащий член смещения $\\theta_0$ и веса $\\theta_1, \\theta_2, \\dots, \\theta_n$. Входной вектор $\\mathbf{x}$ содержит постоянный член $x_0 = 1$, а также все входные функции $x_1, x_2, \\dots, x_n$. *\n",
        "\n",
        "*Поскольку мы хотим иметь возможность делать прогнозы для нескольких экземпляров за раз, мы будем использовать матрицу ввода $\\mathbf{X}$, а не один входной вектор. $i^{th}$ строка будет содержать транспонирование $i^{th}$ входного вектора  $(\\mathbf{x}^{(i)})^T$. Тогда можно оценить вероятность того, что каждый экземпляр принадлежит положительному классу, используя следующее уравнение:*\n",
        "\n",
        "$ \\hat{\\mathbf{p}} = \\sigma(\\mathbf{X} \\boldsymbol{\\theta})$\n",
        "\n",
        "*Это все, что нам нужно для создания модели: *"
      ]
    },
    {
      "metadata": {
        "id": "eg_Pf4EcOZDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n_inputs + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "logits = tf.matmul(X, theta, name=\"logits\")\n",
        "y_proba = 1 / (1 + tf.exp(-logits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYyOC_cJOZDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In fact, TensorFlow has a nice function `tf.sigmoid()` that we can use to simplify the last line of the previous code:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Фактически, TensorFlow имеет удобную функцию tf.sigmoid (), которую мы можем использовать для упрощения последней строки предыдущего кода:"
      ]
    },
    {
      "metadata": {
        "id": "gmPPThYHOZDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_proba = tf.sigmoid(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPbmE-tuOZDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we saw in chapter 4, the log loss is a good cost function to use for Logistic Regression:\n",
        "\n",
        "*Как мы видели в главе 4, логарифмическая потеря - это хорошая функция стоимости, которую можно использовать для логистической регрессии:*\n",
        "\n",
        "$J(\\boldsymbol{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} \\log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) \\log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}$\n",
        "\n",
        "One option is to implement it ourselves:\n",
        "\n",
        "*Один из вариантов - реализовать ее самим:*"
      ]
    },
    {
      "metadata": {
        "id": "lu5T-2eLOZDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epsilon = 1e-7  # to avoid an overflow when computing the log\n",
        "loss = -tf.reduce_mean(y * tf.log(y_proba + epsilon) + (1 - y) * tf.log(1 - y_proba + epsilon))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xmPjBH7FOZDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "But we might as well use TensorFlow's `tf.losses.log_loss()` function:\n",
        "\n",
        "*Но мы могли бы также использовать функцию tf.losses.log_loss() TensorFlow:*"
      ]
    },
    {
      "metadata": {
        "id": "2eEK0F0BOZDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = tf.losses.log_loss(y, y_proba)  # uses epsilon = 1e-7 by default"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wpFbLHikOZDg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The rest is pretty standard: let's create the optimizer and tell it to minimize the cost function:\n",
        "\n",
        "*Остальное довольно стандартно: создадим оптимизатор и скажем минимизировать функцию стоимости:*"
      ]
    },
    {
      "metadata": {
        "id": "P129B0kOOZDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KlELElWpOZDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All we need now (in this minimal version) is the variable initializer:\n",
        "\n",
        "*Все, что нам нужно (в этой минимальной версии) - это инициализатор переменной:*"
      ]
    },
    {
      "metadata": {
        "id": "88f-mLyBOZDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Nvrcn5kOZDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And we are ready to train the model and use it for predictions!\n",
        "\n",
        "*И мы готовы обучить модель и использовать ее для предсказаний!* "
      ]
    },
    {
      "metadata": {
        "id": "I-G3Lw_HOZDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There's really nothing special about this code, it's virtually the same as the one we used earlier for Linear Regression:\n",
        "\n",
        "*В этом коде нет ничего особенного, это практически то же самое, что мы делали ранее для линейной регрессии:*"
      ]
    },
    {
      "metadata": {
        "id": "FJ9Y_IksOZDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 1000\n",
        "batch_size = 50\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        loss_val = loss.eval({X: X_test, y: y_test})\n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
        "\n",
        "    y_proba_val = y_proba.eval(feed_dict={X: X_test, y: y_test})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BUILMGaOZDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: we don't use the epoch number when generating batches, so we could just have a single `for` loop rather than 2 nested `for` loops, but it's convenient to think of training time in terms of number of epochs (i.e., roughly the number of times the algorithm went through the training set).\n",
        "\n",
        "*Примечание: мы не используем номер эпохи при создании партий, поэтому у нас может быть только один цикл, а не два вложенных, но удобнее думать о времени обучения с точки зрения количества эпох (т. е. примерно число раз алгоритм прошел через набор тренировок).*"
      ]
    },
    {
      "metadata": {
        "id": "hNfkYRBnOZDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each instance in the test set, `y_proba_val` contains the estimated probability that it belongs to the positive class, according to the model. For example, here are the first 5 estimated probabilities:\n",
        "\n",
        "*Для каждого экземпляра в тестовом наборе y_proba_val содержит оценочную вероятность того, что он принадлежит к положительному классу, согласно модели. Например, здесь приведены первые 5 оценочных вероятностей:*"
      ]
    },
    {
      "metadata": {
        "id": "yMGOhFePOZDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_proba_val[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GwBEWMjBOZDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To classify each instance, we can go for maximum likelihood: classify as positive any instance whose estimated probability is greater or equal to 0.5:\n",
        "\n",
        "*Чтобы классифицировать каждый экземпляр, мы можем использовать максимальную вероятность: классифицировать как положительный любой экземпляр, чья предполагаемая вероятность больше или равна 0,5:*"
      ]
    },
    {
      "metadata": {
        "id": "K6CY7Sd8OZDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = (y_proba_val >= 0.5)\n",
        "y_pred[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4K68uubsOZDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Depending on the use case, you may want to choose a different threshold than 0.5: make it higher if you want high precision (but lower recall), and make it lower if you want high recall (but lower precision). See chapter 3 for more details.\n",
        "\n",
        "*В зависимости от варианта использования вы можете выбрать другой порог, нежели 0,5: сделать его больше, если вы хотите высокую точность (но более низкий отзыв), и уменьшите его, если хотите получить высокий уровень отзыва (но более низкую точность). Подробнее см. Главу 3. *"
      ]
    },
    {
      "metadata": {
        "id": "wRQH4nTmOZDv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's compute the model's precision and recall:\n",
        "\n",
        "Давайте вычислим точность модели и отзыв:"
      ]
    },
    {
      "metadata": {
        "id": "nFeTfb6eOZDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukvKb_6_OZDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "recall_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8AuSwrk7OZD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's plot these predictions to see what they look like:\n",
        "\n",
        "*Давайте построим эти прогнозы, чтобы оценить их:*"
      ]
    },
    {
      "metadata": {
        "id": "tGJRhDGfOZD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
        "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
        "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uRnxNpNdOZD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Well, that looks pretty bad, doesn't it? But let's not forget that the Logistic Regression model has a linear decision boundary, so this is actually close to the best we can do with this model (unless we add more features, as we will show in a second).\n",
        "\n",
        "*Ну, это выглядит довольно плохо, не так ли? Но давайте не будем забывать, что модель логистической регрессии имеет линейную границу решения, поэтому на самом деле это близко к лучшему, что мы можем сделать с этой моделью (если мы не добавим больше функций, как мы покажем через секунду).*"
      ]
    },
    {
      "metadata": {
        "id": "gwxib0IYOZD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's start over, but this time we will add all the bells and whistles, as listed in the exercise:\n",
        "* Define the graph within a `logistic_regression()` function that can be reused easily.\n",
        "* Save checkpoints using a `Saver` at regular intervals during training, and save the final model at the end of training.\n",
        "* Restore the last checkpoint upon startup if training was interrupted.\n",
        "* Define the graph using nice scopes so the graph looks good in TensorBoard.\n",
        "* Add summaries to visualize the learning curves in TensorBoard.\n",
        "* Try tweaking some hyperparameters such as the learning rate or the mini-batch size and look at the shape of the learning curve.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Теперь давайте начнем, но на этот раз мы добавим все украшения, как указано в упражнении:\n",
        "* Определите внутри функции `logistic_regression()` граф, которую можно легко использовать повторно.\n",
        "* Сохраняйте контрольные точки с помощью «Saver» через регулярные промежутки времени во время обучения и сохраните окончательную модель в конце обучения.\n",
        "* Восстановить последнюю контрольную точку при запуске, если обучение было прервано.\n",
        "* Определите граф, используя пространства имен, чтобы граф хорошо выглядел  в TensorBoard.\n",
        "* Добавьте резюме для визуализации кривых обучения в TensorBoard.\n",
        "* Попробуйте настроить некоторые гиперпараметры, такие как скорость обучения или размер мини-пакета, и посмотрите на форму кривой обучения."
      ]
    },
    {
      "metadata": {
        "id": "7OwS8rYJOZD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before we start, we will add 4 more features to the inputs: ${x_1}^2$, ${x_2}^2$, ${x_1}^3$ and ${x_2}^3$. This was not part of the exercise, but it will demonstrate how adding features can improve the model. We will do this manually, but you could also add them using `sklearn.preprocessing.PolynomialFeatures`.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Прежде чем мы начнем, мы добавим еще 4 фичи к входам: ${x_1}^2$, ${x_2}^2$, ${x_1}^3$ и ${x_2}^3$. Это не было частью упражнения, но оно продемонстрирует, как добавление фич может улучшить модель. Мы сделаем это вручную, но вы также можете добавить их, используя `sklearn.preprocessing.PolynomialFeatures`."
      ]
    },
    {
      "metadata": {
        "id": "GOvH-FyPOZD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_enhanced = np.c_[X_train,\n",
        "                         np.square(X_train[:, 1]),\n",
        "                         np.square(X_train[:, 2]),\n",
        "                         X_train[:, 1] ** 3,\n",
        "                         X_train[:, 2] ** 3]\n",
        "X_test_enhanced = np.c_[X_test,\n",
        "                        np.square(X_test[:, 1]),\n",
        "                        np.square(X_test[:, 2]),\n",
        "                        X_test[:, 1] ** 3,\n",
        "                        X_test[:, 2] ** 3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOB-snNMOZD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is what the \"enhanced\" training set looks like:\n",
        "\n",
        "Вот как выглядит «улучшенный» набор тренировок:"
      ]
    },
    {
      "metadata": {
        "id": "beT5y27uOZD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_enhanced[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "91q9cegvOZD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ok, next let's reset the default graph:\n",
        "\n",
        "*Итак, затем возьмем граф по умолчанию:*"
      ]
    },
    {
      "metadata": {
        "id": "ZovR3CFnOZD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tiRbYNjXOZD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's define the `logistic_regression()` function to create the graph. We will leave out the definition of the inputs `X` and the targets `y`. We could include them here, but leaving them out will make it easier to use this function in a wide range of use cases (e.g. perhaps we will want to add some preprocessing steps for the inputs before we feed them to the Logistic Regression model).\n",
        "\n",
        "Теперь давайте определим функцию  `logistic_regression()` для создания графа. Мы будем опускать определение входов X и целей y. Мы могли бы включить их здесь, но их исключение упростит использование этой функции в широком диапазоне вариантов (например, возможно, нам захочется добавить некоторые шаги предварительной обработки для входных данных, прежде чем мы будем их комбинировать с моделью логистической регрессии)."
      ]
    },
    {
      "metadata": {
        "id": "L_JAlB1EOZD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def logistic_regression(X, y, initializer=None, seed=42, learning_rate=0.01):\n",
        "    n_inputs_including_bias = int(X.get_shape()[1])\n",
        "    with tf.name_scope(\"logistic_regression\"):\n",
        "        with tf.name_scope(\"model\"):\n",
        "            if initializer is None:\n",
        "                initializer = tf.random_uniform([n_inputs_including_bias, 1], -1.0, 1.0, seed=seed)\n",
        "            theta = tf.Variable(initializer, name=\"theta\")\n",
        "            logits = tf.matmul(X, theta, name=\"logits\")\n",
        "            y_proba = tf.sigmoid(logits)\n",
        "        with tf.name_scope(\"train\"):\n",
        "            loss = tf.losses.log_loss(y, y_proba, scope=\"loss\")\n",
        "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "            training_op = optimizer.minimize(loss)\n",
        "            loss_summary = tf.summary.scalar('log_loss', loss)\n",
        "        with tf.name_scope(\"init\"):\n",
        "            init = tf.global_variables_initializer()\n",
        "        with tf.name_scope(\"save\"):\n",
        "            saver = tf.train.Saver()\n",
        "    return y_proba, loss, training_op, loss_summary, init, saver"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rzbfkV5kOZEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's create a little function to get the name of the log directory to save the summaries for Tensorboard:\n",
        "\n",
        "*Давайте создадим небольшую функцию, чтобы получить имя каталога журнала, чтобы сохранить сводки для Tensorboard:*"
      ]
    },
    {
      "metadata": {
        "id": "tg7vIkgNOZEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def log_dir(prefix=\"\"):\n",
        "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "    root_logdir = \"tf_logs\"\n",
        "    if prefix:\n",
        "        prefix += \"-\"\n",
        "    name = prefix + \"run-\" + now\n",
        "    return \"{}/{}/\".format(root_logdir, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ShkTXROkOZEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, let's create the graph, using the `logistic_regression()` function. We will also create the `FileWriter` to save the summaries to the log directory for Tensorboard:\n",
        "\n",
        "*Затем создадим граф, используя функцию `logistic_regression ()`. Мы также создадим «FileWriter», чтобы сохранить сводки в каталоге журнала для Tensorboard:*"
      ]
    },
    {
      "metadata": {
        "id": "Vf9R_CK-OZEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_inputs = 2 + 4\n",
        "logdir = log_dir(\"logreg\")\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "\n",
        "y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)\n",
        "\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsaA2quyOZEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At last we can train the model! We will start by checking whether a previous training session was interrupted, and if so we will load the checkpoint and continue training from the epoch number we saved. In this example we just save the epoch number to a separate file, but in chapter 11 we will see how to store the training step directly as part of the model, using a non-trainable variable called `global_step` that we pass to the optimizer's `minimize()` method.\n",
        "\n",
        "You can try interrupting training to verify that it does indeed restore the last checkpoint when you start it again.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*Наконец, мы можем обучить модель! Мы начнем с проверки того, была ли прервана предыдущая тренировка, и если это так, мы загрузим контрольно-пропускной пункт и продолжим обучение с сохраненного нами номера эпохи. В этом примере мы просто сохраняем номер эпохи в отдельный файл, но в главе 11 мы увидим, как сохранить шаг обучения непосредственно как часть модели, используя не обучаемую переменную `global_step`, которую мы передаем  оптимизатору  `minimize()`.*\n",
        "\n",
        "*Вы можете попробовать прервать обучение, чтобы убедиться, что он действительно восстанавливает последнюю контрольную точку, когда вы начинаете ее снова.*"
      ]
    },
    {
      "metadata": {
        "id": "5zEeU24iOZEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 10001\n",
        "batch_size = 50\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "checkpoint_path = \"/tmp/my_logreg_model.ckpt\"\n",
        "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
        "final_model_path = \"./my_logreg_model\"\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    if os.path.isfile(checkpoint_epoch_path):\n",
        "        # if the checkpoint file exists, restore the model and load the epoch number\n",
        "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
        "            start_epoch = int(f.read())\n",
        "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
        "        saver.restore(sess, checkpoint_path)\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        sess.run(init)\n",
        "\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
        "        file_writer.add_summary(summary_str, epoch)\n",
        "        if epoch % 500 == 0:\n",
        "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
        "            saver.save(sess, checkpoint_path)\n",
        "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
        "                f.write(b\"%d\" % (epoch + 1))\n",
        "\n",
        "    saver.save(sess, final_model_path)\n",
        "    y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
        "    os.remove(checkpoint_epoch_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7l0EBJvOZEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once again, we can make predictions by just classifying as positive all the instances whose estimated probability is greater or equal to 0.5:\n",
        "\n",
        "*Еще раз, мы можем делать прогнозы, просто классифицируя как положительные все экземпляры, чья оценочная вероятность больше или равна 0,5:*"
      ]
    },
    {
      "metadata": {
        "id": "hX8sG0psOZEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = (y_proba_val >= 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJQBHhLAOZEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "precision_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qN0UXmSmOZEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "recall_score(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9kC7e4OuOZEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
        "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
        "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IBnpQqoYOZEe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that's much, much better! Apparently the new features really helped a lot."
      ]
    },
    {
      "metadata": {
        "id": "BowtP7llqXBC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5vQ3J1coOZEe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try starting the tensorboard server, find the latest run and look at the learning curve (i.e., how the loss evaluated on the test set evolves as a function of the epoch number):\n",
        "\n",
        "```\n",
        "$ tensorboard --logdir=tf_logs\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "qxACrnxbOZEe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now you can play around with the hyperparameters (e.g. the `batch_size` or the `learning_rate`) and run training again and again, comparing the learning curves. You can even automate this process by implementing grid search or randomized search. Below is a simple implementation of a randomized search on both the batch size and the learning rate. For the sake of simplicity, the checkpoint mechanism was removed.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Теперь это намного, намного лучше! По-видимому, новые функции действительно помогли.\n",
        "\n",
        "Попробуйте запустить tensorboard server, найдите последний прогон и посмотрите на кривую обучения (то есть, как оценка потерь на тестовом наборе эволюционирует как функция номера эпохи):\n",
        "\n",
        "```\n",
        "$ tensorboard --logdir = tf_logs\n",
        "```\n",
        "\n",
        "Теперь вы можете играть с гиперпараметрами (например, `batch_size` или `learning_rate`) и снова и снова проводить обучение, сравнивая кривые обучения. Вы даже можете автоматизировать этот процесс, выполнив поиск по сетке или рандомизированный поиск. Ниже представлена простая реализация рандомизированного поиска как размера батча, так и скорости обучения. Для простоты был удален механизм контрольной точки."
      ]
    },
    {
      "metadata": {
        "id": "TpQYgu1XOZEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import reciprocal\n",
        "\n",
        "n_search_iterations = 10\n",
        "\n",
        "for search_iteration in range(n_search_iterations):\n",
        "    batch_size = np.random.randint(1, 100)\n",
        "    learning_rate = reciprocal(0.0001, 0.1).rvs(random_state=search_iteration)\n",
        "\n",
        "    n_inputs = 2 + 4\n",
        "    logdir = log_dir(\"logreg\")\n",
        "    \n",
        "    print(\"Iteration\", search_iteration)\n",
        "    print(\"  logdir:\", logdir)\n",
        "    print(\"  batch size:\", batch_size)\n",
        "    print(\"  learning_rate:\", learning_rate)\n",
        "    print(\"  training: \", end=\"\")\n",
        "\n",
        "    reset_graph()\n",
        "\n",
        "    X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
        "    y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "\n",
        "    y_proba, loss, training_op, loss_summary, init, saver = logistic_regression(\n",
        "        X, y, learning_rate=learning_rate)\n",
        "\n",
        "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
        "\n",
        "    n_epochs = 10001\n",
        "    n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "    final_model_path = \"./my_logreg_model_%d\" % search_iteration\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            for batch_index in range(n_batches):\n",
        "                X_batch, y_batch = random_batch(X_train_enhanced, y_train, batch_size)\n",
        "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "            loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test_enhanced, y: y_test})\n",
        "            file_writer.add_summary(summary_str, epoch)\n",
        "            if epoch % 500 == 0:\n",
        "                print(\".\", end=\"\")\n",
        "\n",
        "        saver.save(sess, final_model_path)\n",
        "\n",
        "        print()\n",
        "        y_proba_val = y_proba.eval(feed_dict={X: X_test_enhanced, y: y_test})\n",
        "        y_pred = (y_proba_val >= 0.5)\n",
        "        \n",
        "        print(\"  precision:\", precision_score(y_test, y_pred))\n",
        "        print(\"  recall:\", recall_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z6ZMXImxOZEe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `reciprocal()` function from SciPy's `stats` module returns a random distribution that is commonly used when you have no idea of the optimal scale of a hyperparameter. See the exercise solutions for chapter 2 for more details.\n",
        "\n",
        "*Функция `reciprocal ()` из модуля `stats` SciPy возвращает случайное распределение, которое обычно используется, когда вы не знаете оптимального масштаба гиперпараметра. Подробнее см. Решения для упражнений для главы 2. *"
      ]
    },
    {
      "metadata": {
        "id": "g6GH-NAIOZEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tg1nh_njXW2H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}