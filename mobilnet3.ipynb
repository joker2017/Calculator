{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilnet2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joker2017/Calculator/blob/master/mobilnet3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ZaqNYJTliID_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Существует три типа методов тонкой настройки tenorflow:\n",
        "\n",
        "*  Ручная настройка с использованием структуры сети и весов, встроенных в TF-Slim\n",
        "* Автоматизируйте сборку с помощью скрипта train_image_classifier.py, предоставленного tf-slim, вот как\n",
        "* Используя tf.keras, процесс такой же, как и keras\n",
        "\n",
        "Здесь в основном представим первый метод выше, обратите внимание:\n",
        "\n",
        "* *Tensorflow/models* удален из мэйнфрейма tf после версии 1.0. Его необходимо загрузить вручную. Здесь находится [tensorflow/models](http://link.zhihu.com/?target=https%3A//github.com/tensorflow/models). Вы можете использовать *git clone*, чтобы загрузить его в локальный каталог. Используйте следующую команду, чтобы временно добавить его в путь поиска python ."
      ]
    },
    {
      "metadata": {
        "id": "b4ommrQI8Hrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c31bb346-e68c-4bab-c90d-7ce4fecd574b"
      },
      "cell_type": "code",
      "source": [
        "!ls \"./content/models\""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access './content/models': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8R8WJMUU8F4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "838e63c4-75f2-430f-bb83-7fc122310b42"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d66l0rfG-K4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "20d31455-59d3-4ba2-c479-6cc412c5c43f"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from IPython import display \n",
        "checkpoint_name = 'mobilenet_v2_1.0_224' #@param\n",
        "base_name = checkpoint_name\n",
        "url = 'https://storage.googleapis.com/mobilenet_v2/checkpoints/' + checkpoint_name + '.tgz'\n",
        "print('Downloading from ', url)\n",
        "!wget {url}\n",
        "print('Unpacking')\n",
        "!tar -xvf {base_name}.tgz\n",
        "checkpoint = base_name + '.ckpt'\n",
        "\n",
        "display.clear_output()\n",
        "print('Successfully downloaded checkpoint from ', url,\n",
        "      '. It is available as', checkpoint)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded checkpoint from  https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.0_224.tgz . It is available as mobilenet_v2_1.0_224.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YfGjeuq0ik4U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Файл контрольных точек сети предварительного обучения Tf-slim в файле tensorflow/models/research/slim, [общие веса предварительного обучения сети](http://link.zhihu.com/?target=https%3A//github.com/tensorflow/models/blob/master/research/slim/README.md)\n",
        "* Файл контрольных точек сети предварительной подготовки мобильной сети указан более конкретно в файлах slim/nets/mobilenet и [Mobilenet](http://link.zhihu.com/?target=https%3A//github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md).\n"
      ]
    },
    {
      "metadata": {
        "id": "828OacMijzZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGeVvsS8jXN8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.1 Метод построения модели"
      ]
    },
    {
      "metadata": {
        "id": "rFAVFO3cjevS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Существует три метода для тензорного потока для восстановления структуры и весов модели из файла контрольных точек.После восстановления перечисленных здесь моделей вычисления прямого деривации могут быть непосредственно выполнены для прогнозного анализа"
      ]
    },
    {
      "metadata": {
        "id": "sME02WGej08r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1) Загрузите структуру графика напрямую, затем загрузите вес**"
      ]
    },
    {
      "metadata": {
        "id": "KTXqWOTXjbon",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import_meta_graph можно загрузить структуру графика непосредственно из метафайла\n",
        "saver = tf.train.import_meta_graph(os.path.join(model_path,r\"resnet_v2/model.ckpt-258931.meta\"))\n",
        "\n",
        "# allow_soft_placement автоматический выбор устройства\n",
        "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
        "    # latest_checkpoint Проверить файл контрольной точки, чтобы найти последнюю модель\n",
        "    # restore Восстановить вес графика\n",
        "    saver.restore(sess,tf.train.latest_checkpoint(r\"./model/resnet_v2\"))\n",
        "    graph = sess.graph\n",
        "    # Get_tensor_by_name Получить тензор по имени тензорного\n",
        "    print(sess.run(graph.get_tensor_by_name(\"resnet_model/conv2d/kernel:0\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8XvmpffGY8S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Временно добавить slim в путь поиска Python\n",
        "import sys\n",
        "sys.path.append('/content/models/research/slim')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jKy7iV1Lk1NT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2) Сначала построить структуру графика, а затем загрузить вес**"
      ]
    },
    {
      "metadata": {
        "id": "eUatEd9njl8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0520bbdf-e003-414b-d306-d3b3457669f9"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Импорт mobilenet_v2\n",
        "from nets.mobilenet import mobilenet_v2\n",
        "# Сбросить диаграмму \n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Импортировать mobilenet, сначала построить структуру графа.\n",
        "#После загрузки tf.get_default_graph () содержит структуру графа расчета mobilenet. \n",
        "#Вы можете использовать tf.get_collection (tf.GraphKeys.TRAINABLE_VARIABLES), \n",
        "#чтобы сравнить разницу до и после reset_graph’‘’\n",
        "\n",
        "images = tf.placeholder(tf.float32,(None,224,224,3))\n",
        "with tf.contrib.slim.arg_scope(mobilenet_v2.training_scope(is_training=False)):\n",
        "    logits, endpoints = mobilenet_v2.mobilenet(images) #depth_multiplier=1.4\n",
        "\n",
        "# Определить класс 'saver' для восстановления весов графа\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "# latest_checkpoint Проверить файл контрольной точки, чтобы найти последнюю модель\n",
        "# restore Восстановить вес графика\n",
        "    saver.restore(sess, checkpoint) #\"tf.train.latest_checkpoint(./model_ckpt/mobilenet_v2)\"\n",
        "# get_tensor_by_name Получить тензор по имени тензорного\n",
        "    print(sess.run(tf.get_default_graph().get_tensor_by_name(\"MobilenetV2/Conv/weights:0\")).shape)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from mobilenet_v2_1.0_224.ckpt\n",
            "(3, 3, 3, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BtIA3uUbmSpg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Выведите имя узла в структуре графа. Имя тензора должно иметь номер, например 0, для обозначения первого вывода вычислительного узла:"
      ]
    },
    {
      "metadata": {
        "id": "CguPMI1DAoKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dccb064-81c2-44b2-9713-ac923bcc514f"
      },
      "cell_type": "code",
      "source": [
        "logits.op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'MobilenetV2/embedding:0' shape=(?, 7, 7, 1280) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "Rp7Ct6QSmVpy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1304
        },
        "outputId": "3cc0eaf3-f029-4de1-bcc4-26a00d40a152"
      },
      "cell_type": "code",
      "source": [
        "#for var in tf.trainable_variables():\n",
        "  #print(var.name)\n",
        "endpoints\n",
        "#logits.op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0].op.inputs[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Logits': <tf.Tensor 'MobilenetV2/Logits/output:0' shape=(?, 1001) dtype=float32>,\n",
              " 'Predictions': <tf.Tensor 'MobilenetV2/Predictions/Reshape_1:0' shape=(?, 1001) dtype=float32>,\n",
              " 'global_pool': <tf.Tensor 'MobilenetV2/Logits/AvgPool:0' shape=(?, 1, 1, 1280) dtype=float32>,\n",
              " 'layer_1': <tf.Tensor 'MobilenetV2/Conv/Relu6:0' shape=(?, 112, 112, 32) dtype=float32>,\n",
              " 'layer_10': <tf.Tensor 'MobilenetV2/expanded_conv_8/output:0' shape=(?, 14, 14, 64) dtype=float32>,\n",
              " 'layer_10/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_8/depthwise_output:0' shape=(?, 14, 14, 384) dtype=float32>,\n",
              " 'layer_10/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_8/expansion_output:0' shape=(?, 14, 14, 384) dtype=float32>,\n",
              " 'layer_10/output': <tf.Tensor 'MobilenetV2/expanded_conv_8/output:0' shape=(?, 14, 14, 64) dtype=float32>,\n",
              " 'layer_11': <tf.Tensor 'MobilenetV2/expanded_conv_9/output:0' shape=(?, 14, 14, 64) dtype=float32>,\n",
              " 'layer_11/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_9/depthwise_output:0' shape=(?, 14, 14, 384) dtype=float32>,\n",
              " 'layer_11/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_9/expansion_output:0' shape=(?, 14, 14, 384) dtype=float32>,\n",
              " 'layer_11/output': <tf.Tensor 'MobilenetV2/expanded_conv_9/output:0' shape=(?, 14, 14, 64) dtype=float32>,\n",
              " 'layer_12': <tf.Tensor 'MobilenetV2/expanded_conv_10/output:0' shape=(?, 14, 14, 96) dtype=float32>,\n",
              " 'layer_12/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_10/depthwise_output:0' shape=(?, 14, 14, 384) dtype=float32>,\n",
              " 'layer_12/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_10/expansion_output:0' shape=(?, 14, 14, 384) dtype=float32>,\n",
              " 'layer_12/output': <tf.Tensor 'MobilenetV2/expanded_conv_10/output:0' shape=(?, 14, 14, 96) dtype=float32>,\n",
              " 'layer_13': <tf.Tensor 'MobilenetV2/expanded_conv_11/output:0' shape=(?, 14, 14, 96) dtype=float32>,\n",
              " 'layer_13/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_11/depthwise_output:0' shape=(?, 14, 14, 576) dtype=float32>,\n",
              " 'layer_13/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_11/expansion_output:0' shape=(?, 14, 14, 576) dtype=float32>,\n",
              " 'layer_13/output': <tf.Tensor 'MobilenetV2/expanded_conv_11/output:0' shape=(?, 14, 14, 96) dtype=float32>,\n",
              " 'layer_14': <tf.Tensor 'MobilenetV2/expanded_conv_12/output:0' shape=(?, 14, 14, 96) dtype=float32>,\n",
              " 'layer_14/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_12/depthwise_output:0' shape=(?, 14, 14, 576) dtype=float32>,\n",
              " 'layer_14/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_12/expansion_output:0' shape=(?, 14, 14, 576) dtype=float32>,\n",
              " 'layer_14/output': <tf.Tensor 'MobilenetV2/expanded_conv_12/output:0' shape=(?, 14, 14, 96) dtype=float32>,\n",
              " 'layer_15': <tf.Tensor 'MobilenetV2/expanded_conv_13/output:0' shape=(?, 7, 7, 160) dtype=float32>,\n",
              " 'layer_15/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_13/depthwise_output:0' shape=(?, 7, 7, 576) dtype=float32>,\n",
              " 'layer_15/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_13/expansion_output:0' shape=(?, 14, 14, 576) dtype=float32>,\n",
              " 'layer_15/output': <tf.Tensor 'MobilenetV2/expanded_conv_13/output:0' shape=(?, 7, 7, 160) dtype=float32>,\n",
              " 'layer_16': <tf.Tensor 'MobilenetV2/expanded_conv_14/output:0' shape=(?, 7, 7, 160) dtype=float32>,\n",
              " 'layer_16/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_14/depthwise_output:0' shape=(?, 7, 7, 960) dtype=float32>,\n",
              " 'layer_16/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_14/expansion_output:0' shape=(?, 7, 7, 960) dtype=float32>,\n",
              " 'layer_16/output': <tf.Tensor 'MobilenetV2/expanded_conv_14/output:0' shape=(?, 7, 7, 160) dtype=float32>,\n",
              " 'layer_17': <tf.Tensor 'MobilenetV2/expanded_conv_15/output:0' shape=(?, 7, 7, 160) dtype=float32>,\n",
              " 'layer_17/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_15/depthwise_output:0' shape=(?, 7, 7, 960) dtype=float32>,\n",
              " 'layer_17/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_15/expansion_output:0' shape=(?, 7, 7, 960) dtype=float32>,\n",
              " 'layer_17/output': <tf.Tensor 'MobilenetV2/expanded_conv_15/output:0' shape=(?, 7, 7, 160) dtype=float32>,\n",
              " 'layer_18': <tf.Tensor 'MobilenetV2/expanded_conv_16/output:0' shape=(?, 7, 7, 320) dtype=float32>,\n",
              " 'layer_18/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_16/depthwise_output:0' shape=(?, 7, 7, 960) dtype=float32>,\n",
              " 'layer_18/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_16/expansion_output:0' shape=(?, 7, 7, 960) dtype=float32>,\n",
              " 'layer_18/output': <tf.Tensor 'MobilenetV2/expanded_conv_16/output:0' shape=(?, 7, 7, 320) dtype=float32>,\n",
              " 'layer_19': <tf.Tensor 'MobilenetV2/Conv_1/Relu6:0' shape=(?, 7, 7, 1280) dtype=float32>,\n",
              " 'layer_2': <tf.Tensor 'MobilenetV2/expanded_conv/output:0' shape=(?, 112, 112, 16) dtype=float32>,\n",
              " 'layer_2/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv/depthwise_output:0' shape=(?, 112, 112, 32) dtype=float32>,\n",
              " 'layer_2/output': <tf.Tensor 'MobilenetV2/expanded_conv/output:0' shape=(?, 112, 112, 16) dtype=float32>,\n",
              " 'layer_3': <tf.Tensor 'MobilenetV2/expanded_conv_1/output:0' shape=(?, 56, 56, 24) dtype=float32>,\n",
              " 'layer_3/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_1/depthwise_output:0' shape=(?, 56, 56, 96) dtype=float32>,\n",
              " 'layer_3/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_1/expansion_output:0' shape=(?, 112, 112, 96) dtype=float32>,\n",
              " 'layer_3/output': <tf.Tensor 'MobilenetV2/expanded_conv_1/output:0' shape=(?, 56, 56, 24) dtype=float32>,\n",
              " 'layer_4': <tf.Tensor 'MobilenetV2/expanded_conv_2/output:0' shape=(?, 56, 56, 24) dtype=float32>,\n",
              " 'layer_4/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_2/depthwise_output:0' shape=(?, 56, 56, 144) dtype=float32>,\n",
              " 'layer_4/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_2/expansion_output:0' shape=(?, 56, 56, 144) dtype=float32>,\n",
              " 'layer_4/output': <tf.Tensor 'MobilenetV2/expanded_conv_2/output:0' shape=(?, 56, 56, 24) dtype=float32>,\n",
              " 'layer_5': <tf.Tensor 'MobilenetV2/expanded_conv_3/output:0' shape=(?, 28, 28, 32) dtype=float32>,\n",
              " 'layer_5/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_3/depthwise_output:0' shape=(?, 28, 28, 144) dtype=float32>,\n",
              " 'layer_5/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_3/expansion_output:0' shape=(?, 56, 56, 144) dtype=float32>,\n",
              " 'layer_5/output': <tf.Tensor 'MobilenetV2/expanded_conv_3/output:0' shape=(?, 28, 28, 32) dtype=float32>,\n",
              " 'layer_6': <tf.Tensor 'MobilenetV2/expanded_conv_4/output:0' shape=(?, 28, 28, 32) dtype=float32>,\n",
              " 'layer_6/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_4/depthwise_output:0' shape=(?, 28, 28, 192) dtype=float32>,\n",
              " 'layer_6/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_4/expansion_output:0' shape=(?, 28, 28, 192) dtype=float32>,\n",
              " 'layer_6/output': <tf.Tensor 'MobilenetV2/expanded_conv_4/output:0' shape=(?, 28, 28, 32) dtype=float32>,\n",
              " 'layer_7': <tf.Tensor 'MobilenetV2/expanded_conv_5/output:0' shape=(?, 28, 28, 32) dtype=float32>,\n",
              " 'layer_7/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_5/depthwise_output:0' shape=(?, 28, 28, 192) dtype=float32>,\n",
              " 'layer_7/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_5/expansion_output:0' shape=(?, 28, 28, 192) dtype=float32>,\n",
              " 'layer_7/output': <tf.Tensor 'MobilenetV2/expanded_conv_5/output:0' shape=(?, 28, 28, 32) dtype=float32>,\n",
              " 'layer_8': <tf.Tensor 'MobilenetV2/expanded_conv_6/output:0' shape=(?, 14, 14, 64) dtype=float32>,\n",
              " 'layer_8/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_6/depthwise_output:0' shape=(?, 14, 14, 192) dtype=float32>,\n",
              " 'layer_8/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_6/expansion_output:0' shape=(?, 28, 28, 192) dtype=float32>,\n",
              " 'layer_8/output': <tf.Tensor 'MobilenetV2/expanded_conv_6/output:0' shape=(?, 14, 14, 64) dtype=float32>,\n",
              " 'layer_9': <tf.Tensor 'MobilenetV2/expanded_conv_7/output:0' shape=(?, 14, 14, 64) dtype=float32>,\n",
              " 'layer_9/depthwise_output': <tf.Tensor 'MobilenetV2/expanded_conv_7/depthwise_output:0' shape=(?, 14, 14, 384) dtype=float32>,\n",
              " 'layer_9/expansion_output': <tf.Tensor 'MobilenetV2/expanded_conv_7/expansion_output:0' shape=(?, 14, 14, 384) dtype=float32>,\n",
              " 'layer_9/output': <tf.Tensor 'MobilenetV2/expanded_conv_7/output:0' shape=(?, 14, 14, 64) dtype=float32>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "fXNGlEqsmtpG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3) замороженный вывод**"
      ]
    },
    {
      "metadata": {
        "id": "GxzTLCkZmwHz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Файл pb помещает всю структуру значения переменной и графика вычислений в файл и преобразует переменную и значение в константу с помощью convert_variable_to_constants. При проверке модели входные данные нужно только перенаправить на выходной слой."
      ]
    },
    {
      "metadata": {
        "id": "sDIy87tQm7Yx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Прочитайте сохраненный файл pb и проанализируйте его в соответствующем GraphDef Protocol Buffer.\n",
        "gd =  tf.GraphDef.FromString(open('./model_ckpt/mobilenet_v2/mobilenet_v2_1.4_224_frozen.pb',\"rb\").read())\n",
        "# import_graph_def Загрузить график, сохраненный в graphdef, в текущий граф, return_elements возвращает указанный тензор\n",
        "inp, predictions = \\\n",
        "tf.import_graph_def(gd,return_elements=[\"input:0\",\"MobilenetV2/Predictions/Reshape_1:0\"])\n",
        "\n",
        "# График расчета в это время может быть использован непосредственно для прогнозирования\n",
        "# Вытащите картинку! wget https://upload.wikimedia.org/wikipedia/commons/f/fe/Giant_Panda_in_Beijing_Zoo_1.JPG -O panda.jpg\n",
        "from PIL import Image\n",
        "img = np.array(Image.open('panda.jpg').resize((224, 224))).astype(np.float) / 128 - 1\n",
        "# inp - это входные данные, для которых требуется канал, а predictions - это структура прогнозирования, которую необходимо выводить.\n",
        "with tf.Session(graph=inp.graph) as sess:\n",
        "    x = sess.run(predictions,feed_dict={inp:img.reshape(1,224,224,3)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kW_elEGjn0Ju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.2 Finetune Process**"
      ]
    },
    {
      "metadata": {
        "id": "SiP8mZU8n2bT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Построить структуру графика, перехватить целевой тензор, добавить новый слой\n",
        "2. Загрузить целевой тензорный вес\n",
        "3. Тренировка нового слоя\n",
        "4. Глобальная подстройка"
      ]
    },
    {
      "metadata": {
        "id": "SPY4uhWvoKbn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1) Построить структуру графика, перехватить целевой тензор, добавить новый слой**\n",
        "\n",
        "\n",
        "Структура графика на этом этапе представляет собой структуру графика расчета мобильной сети, полученную методом **« сначала построение структуры графика, а затем загрузка веса » .**"
      ]
    },
    {
      "metadata": {
        "id": "6_FmfK6ioamS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Импорт mobilenet_v2\n",
        "from nets.mobilenet import mobilenet_v2\n",
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "# Построить расчетную диаграмму\n",
        "images = tf.placeholder(tf.float32,(None,224,224,3))\n",
        "with tf.contrib.slim.arg_scope(mobilenet_v2.training_scope(is_training=True)):\n",
        "    logits, endpoints = mobilenet_v2.mobilenet(images, depth_multiplier=1.0) #\n",
        "\n",
        "# Получить целевой тензор, добавить новый слой\n",
        "with tf.variable_scope(\"finetune_layers\"):\n",
        "    # Получить целевой тензор и вынуть тензор указанного слоя в mobilenet\n",
        "    mobilenet_tensor = tf.get_default_graph().get_tensor_by_name(\"MobilenetV2/expanded_conv_16/output:0\")   #(\"MobilenetV2/expanded_conv_14/output:0\")\n",
        "    #prelogits = tf.squeeze(endpoints[\"layer_18/output\"], axis=[1, 2])\n",
        "    # Передаем тензор на новый слой\n",
        "    x = tf.layers.Conv2D(filters=256,kernel_size=3,name=\"conv2d_1\")(mobilenet_tensor)\n",
        "    # Наблюдаем, обновляется ли вес нового слоя tf.summary.histogram(\"conv2d_1\",x)\n",
        "    x = tf.nn.relu(x,name=\"relu_1\")\n",
        "    x = tf.layers.Conv2D(filters=256,kernel_size=3,name=\"conv2d_2\")(x)\n",
        "    x = tf.layers.Conv2D(10,3,name=\"conv2d_3\")(x)\n",
        "    predictions = tf.reshape(x, (-1,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HglWWnmoo9MI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Рассчитаем структуру графика:\n",
        "\n",
        "![Рассчитаем структуру графика:](https://pic4.zhimg.com/80/v2-f745afae04881302990bdffe3c5c0bf7_hd.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "HRW8QLq-pY2d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Внутри красного поля находится структура сети Mobilenet. Второй фиолетовый узел сверху вниз - это узел «MobilenetV2/extended_conv_14/output». Видно, что он напрямую связан с finetune_layers."
      ]
    },
    {
      "metadata": {
        "id": "Qyt_VMvTpf7j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2) Загрузите целевые веса и обучите новые слои**"
      ]
    },
    {
      "metadata": {
        "id": "dm0guV64pp0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1086
        },
        "outputId": "9133a438-7ec2-4f7e-fcf3-3ec841137c39"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "# one-hot кодирование\n",
        "#def to_categorical(data, nums):\n",
        "    #return np.eye(nums)\n",
        "# Произвольно генерировать данные\n",
        "x_train = np.random.random(size=(141,224,224,3))\n",
        "y_train = np.random.randint(1001, size=(1, 10))                          #     np.random.sample(1,10)\n",
        "\n",
        "# Конфигурация условий обучения\n",
        "## label Placeholder\n",
        "                           \n",
        "y_label = tf.placeholder(tf.int32, shape=(None,10))\n",
        "#tf.placeholder(tf.float32, shape=(1024, 1024))\n",
        "## Собирайте переменные в пределах области видимости finetune_layers, обновляйте только вес добавленного слоя\n",
        "train_var = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\"finetune_layers\")\n",
        "## Определение потери\n",
        "base_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_label,logits=predictions)\n",
        "loss= tf.reduce_mean(base_loss) \n",
        "## Определите метод оптимизации, используйте var_list, чтобы указать вес для обновления, и обновляйте только вес train_var в это время.\n",
        "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss,var_list=train_var)\n",
        "## Наблюдаем, обновляется ли вес нового слоя\n",
        "tf.summary.histogram(\"mobilenet_conv8\",tf.get_default_graph().get_tensor_by_name('MobilenetV2/expanded_conv_8/depthwise/depthwise_weights:0'))\n",
        "tf.summary.histogram(\"mobilenet_conv9\",tf.get_default_graph().get_tensor_by_name('MobilenetV2/expanded_conv_9/depthwise/depthwise_weights:0'))\n",
        "\n",
        "## Объединить все резюме\n",
        "merge_all = tf.summary.merge_all()\n",
        "\n",
        "## Установите количество итераций и пакетов университетов\n",
        "epochs = 10\n",
        "batch_size =1000\n",
        "\n",
        "# Получить функцию из указанного списка переменных var_list\n",
        "def get_var_list(target_tensor=None):\n",
        "   # '''Получить функцию из указанного списка переменных var_list'''\n",
        "    if target_tensor==None:\n",
        "        target_tensor = \"MobilenetV2/expanded_conv_15/output:0\"\n",
        "    target = target_tensor.split(\"/\")[1]\n",
        "    all_list = []\n",
        "    all_var = []\n",
        "# пройти все переменные, node.name получает имя переменной \n",
        "# Не используйте tf.trainable_variables(), потому что moving_mean/variance, batchnorm не принадлежит к обучаемой переменной\n",
        "    for var in tf.global_variables():\n",
        "        if var != []:\n",
        "            all_list.append(var.name)\n",
        "            all_var.append(var)\n",
        "    try:\n",
        "        all_list = list(map(lambda x:x.split(\"/\")[1],all_list))\n",
        "# Найти индекс соответствующей переменной области видимости\n",
        "        ind = all_list[::-1].index(target)\n",
        "        ind = len(all_list) -  ind - 1\n",
        "        print(ind)\n",
        "        del all_list\n",
        "        return all_var[:ind+1]\n",
        "    except:\n",
        "        print(\"target_tensor is not exist!\")\n",
        "\n",
        "#Имя целевого тензора, чтобы получить список переменных, которые необходимо загрузить весовые коэффициенты из файла var_list\n",
        "target_tensor = \"MobilenetV2/expanded_conv_16/output:0\"\n",
        "var_list = get_var_list(target_tensor)\n",
        "saver = tf.train.Saver(var_list=var_list)\n",
        "\n",
        "# Загрузите веса в файл и обучите новый слой\n",
        "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
        "    writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
        "## Параметры инициализации: загрузка весов из файла train_var. Использовать функцию инициализации.\n",
        "    sess.run(tf.variables_initializer(var_list=train_var))\n",
        "    saver.restore(sess, checkpoint)\n",
        "    \n",
        "    for i in range(2000):\n",
        "        start = (i*batch_size) % x_train.shape[0]\n",
        "        end = min(start+batch_size, x_train.shape[0])\n",
        "        _, merge, losses = sess.run([train_step,merge_all,loss],\\\n",
        "                             feed_dict={images:x_train[start:end],\\\n",
        "                                            y_label:y_train})#[start:end]\n",
        "        if i%1==0:\n",
        "            print(i, losses)\n",
        "            writer.add_summary(merge, i)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "254\n",
            "INFO:tensorflow:Restoring parameters from mobilenet_v2_1.0_224.ckpt\n",
            "0 16585.549\n",
            "1 381458880.0\n",
            "2 1.9825263e+19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-aa257cddc8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmerge_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                                            \u001b[0my_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[start:end]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "x46l45PGsFFk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Особенности инициализации веса:**\n",
        "\n",
        "1. Сначала используйте глобальную инициализацию *tf.global_variables_initializer()*, а затем используйте порядок saver.restore, который не может быть неправильным, иначе загруженный вес будет переинициализирован."
      ]
    },
    {
      "metadata": {
        "id": "L3UOoAnZsOje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.run(tf.global_variables_initializer())\n",
        "saver.restore(sess,tf.train.latest_checkpoint(\"./content\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xt2MATAFIh-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "62b08347-2eb1-4863-c24c-6d001d22732a"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#print( os.getcwd() )\n",
        "print( os.listdir('/content/models') )"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.gitignore', 'samples', '.git', 'CODEOWNERS', 'WORKSPACE', '.gitmodules', 'LICENSE', 'research', 'official', 'README.md', 'tutorials', 'AUTHORS', 'CONTRIBUTING.md', 'ISSUE_TEMPLATE.md']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q-Rx65FosRSy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. Сначала используйте saver.restore для загрузки весов из модели, а затем используйте *tf.variable_initializaer()* для инициализации указанного var_list, порядок можно изменить."
      ]
    },
    {
      "metadata": {
        "id": "SFtY6EUnsXMO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saver.restore(sess,tf.train.latest_checkpoint(\"./content/models/model_ckpt/mobilenet_v2\"))\n",
        "sess.run(tf.variables_initializer(var_list=train_var))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vZIzkc5xsbUj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3. Первые два метода также инициализируют переменные для бесполезных узлов и должны заранее выполнить операцию saver.restore, что означает, что для обеспечения того, чтобы процесс finetune не сообщал об ошибке, требуется две операции save.restore. Теперь вы можете составить var_list, отфильтровав все переменные, которые должны загрузить веса из файла, а затем определить saver = tf.train.Saver (var_list) для выборочной загрузки переменных.\n",
        "\n",
        "**В приведенном выше коде используется третий метод, разница между тремя вышеуказанными методами инициализации может быть тщательно понята. Посмотрите на скриншот ниже.**\n",
        "\n",
        "![alt text](https://pic4.zhimg.com/80/v2-812216ca5067586fd223b5cee6f3571b_hd.jpg)"
      ]
    }
  ]
}