{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joker2017/Calculator/blob/master/TF_Test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QXRh0DPiZRyG"
      },
      "cell_type": "markdown",
      "source": [
        "# Создаем простой граф\n"
      ]
    },
    {
      "metadata": {
        "id": "UdJNPbKAcmwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.Variable (3, name=\"x\")\n",
        "y = tf.Variable (4, name=\"y\")\n",
        "f = x*x*y + y + 2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvJEb-5yeOj1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Добавляем сессию**"
      ]
    },
    {
      "metadata": {
        "id": "9DlhWUFueWam",
        "colab_type": "code",
        "outputId": "97886cbc-465c-46e1-fa36-61c7de26d3aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(x.initializer)\n",
        "sess.run(y.initializer)\n",
        "result = sess.run(f)\n",
        "print(result)\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0UEr22MTfgQu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Упращенная сессия (с автозакрытием)**"
      ]
    },
    {
      "metadata": {
        "id": "b-myuowRfmK2",
        "colab_type": "code",
        "outputId": "832630b6-f952-4f7b-9e1d-58f8e49b15a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "  x.initializer.run()\n",
        "  y.initializer.run()\n",
        "  result = f.eval()\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2PjTHZ-KgqPd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Глобальная инициализация**"
      ]
    },
    {
      "metadata": {
        "id": "Krg9XNAIhHOd",
        "colab_type": "code",
        "outputId": "08263dcd-2f77-4a92-9f7d-d05b62ccd13d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.Variable(3, \"x\")\n",
        "y = tf.Variable(2, \"y\")\n",
        "z = x*x*y + y + 2\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  result = f.eval()\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kx6kYxOrmZU2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Новый отдельный экземпляр графа **"
      ]
    },
    {
      "metadata": {
        "id": "cokyh1Szmgdl",
        "colab_type": "code",
        "outputId": "fbfd64e4-9088-4735-d1c0-724a1d200342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  x2 = tf.Variable(2)\n",
        "  y2 = tf.Variable(6)\n",
        "  Z2 = x2*y2\n",
        "  \n",
        "  init = tf.global_variables_initializer()\n",
        "  sess = tf.InteractiveSession()\n",
        "  init.run()\n",
        "  result2 = Z2.eval()\n",
        "  print(result2)\n",
        "  sess.close()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2lahSw9_qb2Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Оценка в одном прогоне**"
      ]
    },
    {
      "metadata": {
        "id": "xh3JJiAeqj0c",
        "colab_type": "code",
        "outputId": "5a2b9d54-ab0f-42bd-f20d-fa074e6de636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "w = tf.constant(3)\n",
        "x = w + 2\n",
        "y = x + 5 \n",
        "z = x * 3\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  y_val, z_val = sess.run([y,z])\n",
        "  print(y_val)\n",
        "  print(z_val)\n",
        " \n",
        "  sess.close()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CimBu8MdU5w6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Линейная регресия упрощенная**"
      ]
    },
    {
      "metadata": {
        "id": "LIyVDmuatllO",
        "colab_type": "code",
        "outputId": "6462a01a-4e02-428a-dd6a-4f21082f1d85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "reset_graph()   \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "\n",
        "#print(housing.feature_names)\n",
        "#print(housing.DESCR)\n",
        "#print(housing.target.shape)\n",
        "\n",
        "# np.ones создает новый array заполненный 1ми, np.c_ создает новый масив обьединяя 2\n",
        "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]\n",
        "\n",
        "X = tf.constant (housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant (housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
        "\n",
        "XT = tf.transpose(X)\n",
        "theta = tf.matmul (tf.matmul (tf.matrix_inverse(tf.matmul(XT,X)), XT) , y)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  theta_value = theta.eval ()\n",
        "  print(theta_value)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a23d43b65f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-a23d43b65f7e>\u001b[0m in \u001b[0;36mreset_graph\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mreset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "shtCel0-3zHc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Вычисление градиента в ручную и автоматически**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WFM5Gjkxe14r",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "m, n = housing.data.shape\n",
        "\n",
        "n_epochs = 100000\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# нормализация данных\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_housing_data = scaler.fit_transform(housing.data)\n",
        "\n",
        "# np.c_ сращивание матриц, np.ones создание матрицы заполненой нулями\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
        "\n",
        "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "\n",
        "# tf.random_uniform генерировать случайный тензер с заданой формой и диапазоном\n",
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\") \n",
        "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
        "error = y_pred - y\n",
        "\n",
        "# tf.reduce_mean вычисляет среднее значение\n",
        "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
        "\n",
        "#gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
        "gradients = tf.gradients (mse, [theta])[0]\n",
        "\n",
        "# создает узел который будет присваивать переменной новое значение \n",
        "training_op = tf.assign(theta, theta - learning_rate * gradients) \n",
        "init = tf.global_variables_initializer()\n",
        " \n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        if epoch % 100 == 0:\n",
        "           k = y_pred.eval()\n",
        "           print(\"Epoch\", epoch, \"MSE =\", mse.eval(), \"y_pred\", y_pred.shape, \"theta\", theta.shape, \"error\", error.shape, \"X\", X.shape)\n",
        "        sess.run(training_op)\n",
        "    \n",
        "    best_theta = theta.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdVU_PkGyn5Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **Вывод матрицы/тензора **"
      ]
    },
    {
      "metadata": {
        "id": "a3kvoTW_a7FX",
        "colab_type": "code",
        "outputId": "bc641c1e-2734-4f07-ccb7-4022aac4cbca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "g = tf.random_uniform([10 + 1, 1], 0.0, 10.0, seed=42)\n",
        "init_op = tf.initialize_all_variables()\n",
        "h = tf.transpose(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42))\n",
        "k = tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42)\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op) \n",
        "    print (sess.run(h))#распечатать тензор\n",
        "    print (sess.run(k))#распечатать тензор\n",
        "    print(g.get_shape) #получить размер массива статич\n",
        "\n",
        "       \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.9045429   0.35481548  0.5906365   0.51156354 -0.04808879  0.26202965\n",
            "  -0.62795925 -0.7713845  -0.32755637]]\n",
            "[[ 0.9045429 ]\n",
            " [ 0.35481548]\n",
            " [ 0.5906365 ]\n",
            " [ 0.51156354]\n",
            " [-0.04808879]\n",
            " [ 0.26202965]\n",
            " [-0.62795925]\n",
            " [-0.7713845 ]\n",
            " [-0.32755637]]\n",
            "<bound method Tensor.get_shape of <tf.Tensor 'random_uniform_22:0' shape=(11, 1) dtype=float32>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E0pOu-9T6e2R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Использование оптимизатора**"
      ]
    },
    {
      "metadata": {
        "id": "mfQf0tc46oSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9a64bcd-fde0-4709-83dd-79af3b9798b6"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "\n",
        "learning_rate = 0.0001\n",
        "n_epochs = 10000\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_housing_data = scaler.fit_transform(housing.data)\n",
        "\n",
        "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
        "\n",
        "#X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "#y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "\n",
        "def fetch_batch (batch_index, batch_size, epoch):\n",
        "    np.random.seed (epoch * batch_size + batch_index) \n",
        "    indices = np.random.randint (m, size=batch_size) \n",
        "    X_batch = scaled_housing_data_plus_bias [indices]\n",
        "    y_batch = housing.target.reshape(-1, 1) [indices]\n",
        "    return X_batch, y_batch\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eznZuEyXpwyI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta, name=\"prediction\")\n",
        "erorr = y_pred - y\n",
        "mse = tf.reduce_mean(tf.square(erorr), name=\"mse\")\n",
        "#gradients = 2/m * tf.matmul(tf.transpose(X), erorr, name=\"gradients\")\n",
        "#training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer (learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "batch_size = 1000\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "     sess.run(init)\n",
        "     for epoch in range(n_epochs):\n",
        "        for batch_index in range(n_batches):\n",
        "            X_batch, y_batch = fetch_batch (batch_index, batch_size, epoch)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        if epoch % 100 == 0 :\n",
        "            print(\"MSE=%s\" % sess.run(mse, feed_dict={X:X_batch, y:y_batch}))\n",
        "            print(\"epoch\", epoch)\n",
        "            #_, mse_value = sess.run([training_op, mse], feed_dict={X:X_batch, y:y_batch})\n",
        "            #print(\"mse_value=%s\" % mse_value)\n",
        "            \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9LLB7p3A9G1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "38205eb4-ee5a-41f9-b8be-98d63b6653de"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "learning_rate = 0.001\n",
        "epoch = 1000\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "\n",
        "scaler = StandardScaler()\n",
        "california_housing_scaler = scaler.fit_transform(housing.data)\n",
        "\n",
        "california_housing_scaler_with_bias = np.c_[np.ones((m, 1)), california_housing_scaler]\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
        "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
        "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
        "y_pred = tf.matmul(X, theta)\n",
        "\n",
        "with tf.name_scope(\"lose\") as scope:\n",
        "     erorr = y_pred - y\n",
        "     mse = tf.reduce_mean(tf.square(erorr), name=\"MSE\")\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer (learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(mse)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "def fitch_batch (batch_size, batch_n, epoch_n):\n",
        "    np.random.seed(batch_size * epoch_n + batch_n)\n",
        "    indexed = np.random.randint(m, size=batch_size)\n",
        "    X_batch = california_housing_scaler_with_bias [indexed]\n",
        "    y_batch = housing.target.reshape(-1, 1) [indexed]\n",
        "    return X_batch, y_batch\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  #saver.restore (sess, \"/tmp/my_model_fin.ckpt\")\n",
        "  for epoch_n in range(epoch):\n",
        "    for batch_n in range(n_batches):\n",
        "      X_batch, y_batch = fitch_batch (batch_size, batch_n, epoch_n)\n",
        "      sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "    if epoch_n % 100 == 0:\n",
        "      mse_p = sess.run(mse, feed_dict={X:X_batch, y:y_batch})\n",
        "      print(mse_p)\n",
        "      save_path = saver.save(sess, \"/tmp/my_model.ckpt\")\n",
        "    \n",
        "  save_path = saver.save(sess, \"/tmp/my_model_fin.ckpt\") \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.583357\n",
            "0.5733535\n",
            "0.5721193\n",
            "0.51688707\n",
            "0.5379817\n",
            "0.4978484\n",
            "0.5438165\n",
            "0.48000878\n",
            "0.5129886\n",
            "0.5052237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yQxdIle6Z0eN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1e246ab7-ae5e-4277-80fa-2a6129b09003"
      },
      "cell_type": "code",
      "source": [
        "#вывод графа\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "  saver.restore (sess, \"/tmp/my_model_fin.ckpt\")\n",
        "  print(mse_p)\n",
        "  \n",
        "print(mse.op.name)\n",
        "#show_graph(tf.get_default_graph())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/my_model_fin.ckpt\n",
            "0.5052237\n",
            "lose/MSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kl4_qT8RqOj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#функция для вывода графа\n",
        "#from tensorflow_graph_in_jupyter import show_graph\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
        "    return strip_def\n",
        "\n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}