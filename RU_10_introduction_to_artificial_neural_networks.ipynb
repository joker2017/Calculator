{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RU_10_introduction_to_artificial_neural_networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "A_eMtWJLZlh2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joker2017/Calculator/blob/master/RU_10_introduction_to_artificial_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "btLM9ciZZlhX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Chapter 10 – Introduction to Artificial Neural Networks**"
      ]
    },
    {
      "metadata": {
        "id": "p19NiGNnZlhX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "_This notebook contains all the sample code and solutions to the exercises in chapter 10._"
      ]
    },
    {
      "metadata": {
        "id": "uZtCxE8YZlhX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ]
    },
    {
      "metadata": {
        "id": "GY3tzmgLZlhX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:\n",
        "\n",
        "Во-первых, давайте сделаем так, чтобы этот ноутбук хорошо работал как в python 2, так и в 3, импортировал несколько распространенных модулей, гарантируя, что графики MatplotLib встроены и подготовят функцию для сохранения цифр:"
      ]
    },
    {
      "metadata": {
        "id": "KqKsdz7-ZlhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"ann\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hg3o6AJhZlhX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perceptrons"
      ]
    },
    {
      "metadata": {
        "id": "ZOUshoVJZlhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
        "y = (iris.target == 0).astype(np.int)\n",
        "\n",
        "per_clf = Perceptron(max_iter=100, random_state=42)\n",
        "per_clf.fit(X, y)\n",
        "\n",
        "y_pred = per_clf.predict([[2, 0.5]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IybbD4hvZlhm",
        "colab_type": "code",
        "outputId": "3bfed431-1a37-491b-b6fc-c8f4efa1bbf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "Dhy3i0NaZlhm",
        "colab_type": "code",
        "outputId": "f55670bc-2a1f-4b77-d9fe-41b216d813df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1100
        }
      },
      "cell_type": "code",
      "source": [
        "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
        "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
        "\n",
        "axes = [0, 5, 0, 2]\n",
        "\n",
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
        "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
        "    )\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "y_predict = per_clf.predict(X_new)\n",
        "zz = y_predict.reshape(x0.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
        "\n",
        "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
        "from matplotlib.colors import ListedColormap\n",
        "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
        "\n",
        "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.ylabel(\"Petal width\", fontsize=14)\n",
        "plt.legend(loc=\"lower right\", fontsize=14)\n",
        "plt.axis(axes)\n",
        "\n",
        "save_fig(\"perceptron_iris_plot\")\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving figure perceptron_iris_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-eaf343701116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0msave_fig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"perceptron_iris_plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-da4c0a4d45fe>\u001b[0m in \u001b[0;36msave_fig\u001b[0;34m(fig_id, tight_layout)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtight_layout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, **kwargs)\u001b[0m\n\u001b[1;32m   1832\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1834\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2265\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2267\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2268\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images/ann/perceptron_iris_plot.png'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAEYCAYAAABBfQDEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWUREREQkxf8BT3Y2MnwedsQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4dd9eba9b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6_pnerNWZlhm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Activation functions"
      ]
    },
    {
      "metadata": {
        "id": "yJAnJVl_Zlhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def logit(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def derivative(f, z, eps=0.000001):\n",
        "    return (f(z + eps) - f(z - eps))/(2 * eps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IDR9MPK9Zlh2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = np.linspace(-5, 5, 200)\n",
        "\n",
        "plt.figure(figsize=(11,4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(z, np.sign(z), \"r-\", linewidth=2, label=\"Step\")\n",
        "plt.plot(z, logit(z), \"g--\", linewidth=2, label=\"Logit\")\n",
        "plt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\n",
        "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
        "plt.grid(True)\n",
        "plt.legend(loc=\"center right\", fontsize=14)\n",
        "plt.title(\"Activation functions\", fontsize=14)\n",
        "plt.axis([-5, 5, -1.2, 1.2])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(z, derivative(np.sign, z), \"r-\", linewidth=2, label=\"Step\")\n",
        "plt.plot(0, 0, \"ro\", markersize=5)\n",
        "plt.plot(0, 0, \"rx\", markersize=10)\n",
        "plt.plot(z, derivative(logit, z), \"g--\", linewidth=2, label=\"Logit\")\n",
        "plt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\n",
        "plt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
        "plt.grid(True)\n",
        "#plt.legend(loc=\"center right\", fontsize=14)\n",
        "plt.title(\"Derivatives\", fontsize=14)\n",
        "plt.axis([-5, 5, -0.2, 1.2])\n",
        "\n",
        "save_fig(\"activation_functions_plot\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMVgCBjBZlh2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def heaviside(z):\n",
        "    return (z >= 0).astype(z.dtype)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "def mlp_xor(x1, x2, activation=heaviside):\n",
        "    return activation(-activation(x1 + x2 - 1.5) + activation(x1 + x2 - 0.5) - 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z8nbH-pKZlh2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1s = np.linspace(-0.2, 1.2, 100)\n",
        "x2s = np.linspace(-0.2, 1.2, 100)\n",
        "x1, x2 = np.meshgrid(x1s, x2s)\n",
        "\n",
        "z1 = mlp_xor(x1, x2, activation=heaviside)\n",
        "z2 = mlp_xor(x1, x2, activation=sigmoid)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.contourf(x1, x2, z1)\n",
        "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
        "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
        "plt.title(\"Activation function: heaviside\", fontsize=14)\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.contourf(x1, x2, z2)\n",
        "plt.plot([0, 1], [0, 1], \"gs\", markersize=20)\n",
        "plt.plot([0, 1], [1, 0], \"y^\", markersize=20)\n",
        "plt.title(\"Activation function: sigmoid\", fontsize=14)\n",
        "plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TceTy4oMZlh2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# FNN for MNIST"
      ]
    },
    {
      "metadata": {
        "id": "A_eMtWJLZlh2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using the Estimator API (formerly `tf.contrib.learn`)"
      ]
    },
    {
      "metadata": {
        "id": "xMkjwkXuZliG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RuVGe86zZliG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Warning**: `tf.examples.tutorials.mnist` is deprecated. We will use `tf.keras.datasets.mnist` instead. Moreover, the `tf.contrib.learn` API was promoted to `tf.estimators` and `tf.feature_columns`, and it has changed considerably. In particular, there is no `infer_real_valued_columns_from_input()` function or `SKCompat` class.\n",
        "\n",
        "**Предупреждение** : `tf.examples.tutorials.mnist` устарело. Вместо этого мы будем использовать `tf.keras.datasets.mnist`  . Кроме того, `tf.contrib.learn ` API был повышен до `tf.estimators` и `tf.feature_columns`, и он значительно изменился. В частности, нет `infer_real_valued_columns_from_input()` функции или `SKCompat` класса\n"
      ]
    },
    {
      "metadata": {
        "id": "c-TD7ykSZliG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "y_valid, y_train = y_train[:5000], y_train[5000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKee-oELZliG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[28 * 28])]\n",
        "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[300,100], n_classes=10,\n",
        "                                     feature_columns=feature_cols)\n",
        "\n",
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"X\": X_train}, y=y_train, num_epochs=40, batch_size=50, shuffle=True)\n",
        "dnn_clf.train(input_fn=input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MThiTaNiZliG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
        "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVtL0D_uZliV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "eval_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EYZVxlqZZliV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_iter = dnn_clf.predict(input_fn=test_input_fn)\n",
        "y_pred = list(y_pred_iter)\n",
        "y_pred[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ekEy8byZliV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using plain TensorFlow\n",
        "Использование простого TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "02RZN2_GZliV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "n_inputs = 28*28  # MNIST\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "n_outputs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0z_Kw8kOZliV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfO7XhZMZlil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def neuron_layer(X, n_neurons, name, activation=None):\n",
        "    with tf.name_scope(name):\n",
        "        n_inputs = int(X.get_shape()[1])\n",
        "        stddev = 2 / np.sqrt(n_inputs)\n",
        "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev) # Выводит случайные значения из усеченного нормального распределения.\n",
        "        W = tf.Variable(init, name=\"kernel\")\n",
        "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\") # tf.zeros Создает тензор со всеми элементами, установленными на ноль.\n",
        "        Z = tf.matmul(X, W) + b # tf.matmul умножение\n",
        "        if activation is not None:\n",
        "            return activation(Z)\n",
        "        else:\n",
        "            return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-OqDOXHsZlil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
        "                           activation=tf.nn.relu)\n",
        "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
        "                           activation=tf.nn.relu)\n",
        "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q2ji5N6KZlil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
        "                                                              logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")  # Вычисляет среднее значение элементов по размерам тензора"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_kxdBpNZlil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MrkB2FCzZlil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)#для каждого образца проверяет коректен ли прогноз сети путем проверки соответствует или нет  \n",
        "                                          #самый высокий логит целевому классу он возвращает одномерный тензер, наполненный булевскими значениями \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "                                          # tf.reduce_mean Вычисляет среднее значение элементов по размерам тензора\n",
        "                                          # приводит булевские значения к значениям с плавающей точкой"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGYQZmcMZli0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDygQ6isZli0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 40\n",
        "batch_size = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4UY6BYgZli0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def shuffle_batch(X, y, batch_size):\n",
        "    rnd_idx = np.random.permutation(len(X)) # np.random.permutation Случайно переставляйте последовательность или возвращайте заданный диапазон / len возвращает длину\n",
        "    n_batches = len(X) // batch_size #// целочисленное деление\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):  # np.array_split делит масим на несколько массивов\n",
        "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9pM1trhsZli0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hLb0S2bnZljE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, \"./my_model_final.ckpt\") # or better, use save_path\n",
        "    X_new_scaled = X_test[:20]\n",
        "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
        "    y_pred = np.argmax(Z, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8Tmgfw_ZljE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Predicted classes:\", y_pred)\n",
        "print(\"Actual classes:   \", y_test[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRvA4C0HZljE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from tensorflow_graph_in_jupyter import show_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jkg5fIrcZljE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pCS2zZNwZljU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using `dense()` instead of `neuron_layer()`\n",
        "Использование `dense()` вместо `neuron_layer()`"
      ]
    },
    {
      "metadata": {
        "id": "bYIYxQPnZljU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note: previous releases of the book used `tensorflow.contrib.layers.fully_connected()` rather than `tf.layers.dense()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dense()`, because anything in the contrib module may change or be deleted without notice. The `dense()` function is almost identical to the `fully_connected()` function, except for a few minor differences:\n",
        "* several parameters are renamed: `scope` becomes `name`, `activation_fn` becomes `activation` (and similarly the `_fn` suffix is removed from other parameters such as `normalizer_fn`), `weights_initializer` becomes `kernel_initializer`, etc.\n",
        "* the default `activation` is now `None` rather than `tf.nn.relu`.\n",
        "* a few more differences are presented in chapter 11.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Примечание: предыдущие версии книги использовались, `tensorflow.contrib.layers.fully_connected()` а не `tf.layers.dense()` (которые не существовали, когда была написана эта глава). Теперь предпочтительнее использовать `tf.layers.dense()`, потому что что-либо в модуле contrib может изменяться или удаляться без уведомления. `dense()` Функция почти идентична `fully_connected()` функции, за исключением нескольких незначительных отличий , за исключением:\n",
        "\n",
        "* несколько параметров переименовываются: scope становится name, `activation_fn` становится `activation` (и аналогичным образом ` _fn` суффикс удаляется из других параметров, таких как `normalizer_fn`), `weights_initializer` становится `kernel_initializer` и т. д.\n",
        "* значение по умолчанию activationтеперь, `None` а не `tf.nn.relu`.\n",
        "* еще несколько различий представлены в главе 11.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "6fTTyEMcZljU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_inputs = 28*28  # MNIST\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "n_outputs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRTB_ezvZljU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dpdJg-Y-ZljU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
        "                              activation=tf.nn.relu)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
        "                              activation=tf.nn.relu)\n",
        "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
        "    y_proba = tf.nn.softmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n6Kntf-zZljU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SZxJ2QVxZljU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sk_UKH8tZljj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u6ezWcYAZljj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V5SMyAVvZljj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "n_batches = 50\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "grkSSohqZljj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4A0aIYXZljz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercise solutions"
      ]
    },
    {
      "metadata": {
        "id": "kC_b3JnYZljz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. to 8."
      ]
    },
    {
      "metadata": {
        "id": "vd2fRY13Zljz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "See appendix A."
      ]
    },
    {
      "metadata": {
        "id": "qBZcpbDLZljz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 9."
      ]
    },
    {
      "metadata": {
        "id": "3v6DHJS4Zljz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "_Train a deep MLP on the MNIST dataset and see if you can get over 98% precision. Just like in the last exercise of chapter 9, try adding all the bells and whistles (i.e., save checkpoints, restore the last checkpoint in case of an interruption, add summaries, plot learning curves using TensorBoard, and so on)._\n",
        "\n",
        "Обучите глубокий MLP в наборе данных MNIST и посмотрите, можете ли вы получить более 98% точности. Как и в последнем упражнении главы 9, попробуйте добавить все колокола и свистки (т. Е. Сохранить контрольные точки, восстановить последнюю контрольную точку в случае прерывания, добавить резюме, отобразить кривые обучения с помощью TensorBoard и т. Д.)."
      ]
    },
    {
      "metadata": {
        "id": "9gt4sZivZljz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First let's create the deep net. It's exactly the same as earlier, with just one addition: we add a `tf.summary.scalar()` to track the loss and the accuracy during training, so we can view nice learning curves using TensorBoard.\n",
        "\n",
        "Сначала давайте создадим глубокую сеть. Это точно так же, как и раньше, с одним дополнением: мы добавляем `tf.summary.scalar()` отслеживание потерь и точности во время обучения, поэтому мы можем просматривать хорошие кривые обучения с помощью TensorBoard.\n"
      ]
    },
    {
      "metadata": {
        "id": "v8W-h91ToHuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "reset_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6JE5NmGZljz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "n_inputs = 28*28  # MNIST\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "n_outputs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sNRu7q99lB7X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "y_valid, y_train = y_train[:5000], y_train[5000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ji2YyfQYZljz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUPDkA0FZlkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
        "                              activation=tf.nn.relu)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
        "                              activation=tf.nn.relu)\n",
        "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "suTlft4FZlkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "    loss_summary = tf.summary.scalar('log_loss', loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mR1ck6N5ZlkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V_pdUxk4ZlkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtFaIxzFZlkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ymzA5wp1ZlkS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to define the directory to write the TensorBoard logs to:\n",
        "\n",
        "Теперь нам нужно определить каталог для записи журналов TensorBoard в:"
      ]
    },
    {
      "metadata": {
        "id": "IgZbGLDDZlkS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def log_dir(prefix=\"\"):\n",
        "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "    root_logdir = \"tf_logs\"\n",
        "    if prefix:\n",
        "        prefix += \"-\"\n",
        "    name = prefix + \"run-\" + now\n",
        "    return \"{}/{}/\".format(root_logdir, name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TNXxSKHZZlkS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logdir = log_dir(\"mnist_dnn\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1zos_rVQZlkS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can create the `FileWriter` that we will use to write the TensorBoard logs:\n",
        "\n",
        "Теперь мы можем создать то, `FileWriter` что мы будем использовать для записи журналов TensorBoard:"
      ]
    },
    {
      "metadata": {
        "id": "OwI0-l1PZlkS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "re8Ps9HXZlkS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hey! Why don't we implement early stopping? For this, we are going to need to use the validation set.\n",
        "\n",
        "Привет! Почему бы нам не начать раннюю остановку? Для этого нам понадобится использовать набор проверки."
      ]
    },
    {
      "metadata": {
        "id": "6ZE8MuvmZlkS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m, n = X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lamemB0aZlkS",
        "colab_type": "code",
        "outputId": "b7f6db53-2789-43fc-a99c-60aa563f3a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "n_epochs = 50\n",
        "batch_size = 50\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "checkpoint_path = \"/tmp/my_deep_mnist_model.ckpt\"\n",
        "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
        "final_model_path = \"./my_deep_mnist_model\"\n",
        "\n",
        "best_loss = np.infty # True, если вход конечен; в противном случае значение равно False (ввод - либо положительная бесконечность, либо отрицательная бесконечность, либо не номер)\n",
        "epochs_without_progress = 0\n",
        "max_epochs_without_progress = 50\n",
        "\n",
        "\n",
        "def shuffle_batch(X, y, batch_size):\n",
        "    rnd_idx = np.random.permutation(len(X)) # np.random.permutation Случайно переставляйте последовательность или возвращайте заданный диапазон / len возвращает длину\n",
        "    n_batches = len(X) // batch_size #// целочисленное деление\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):  # np.array_split делит масим на несколько массивов\n",
        "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "        yield X_batch, y_batch\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    if os.path.isfile(checkpoint_epoch_path):\n",
        "        # if the checkpoint file exists, restore the model and load the epoch number\n",
        "        # если файл контрольной точки существует, восстановите модель и загрузите номер эпохи\n",
        "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
        "            start_epoch = int(f.read())\n",
        "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
        "        saver.restore(sess, checkpoint_path)\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        sess.run(init)\n",
        "\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val, loss_val, accuracy_summary_str, loss_summary_str = sess.run([accuracy, loss, accuracy_summary, loss_summary], feed_dict={X: X_valid, y: y_valid})\n",
        "       # file_writer.add_summary(accuracy_summary_str, epoch)\n",
        "       # file_writer.add_summary(loss_summary_str, epoch)\n",
        "        if epoch % 5 == 0:\n",
        "            print(\"Epoch:\", epoch,\n",
        "                  \"\\tValidation accuracy: {:.3f}%\".format(accuracy_val * 100),\n",
        "                  \"\\tLoss: {:.5f}\".format(loss_val))\n",
        "            saver.save(sess, checkpoint_path)\n",
        "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
        "                f.write(b\"%d\" % (epoch + 1))\n",
        "            if loss_val < best_loss:\n",
        "                saver.save(sess, final_model_path)\n",
        "                best_loss = loss_val\n",
        "            else:\n",
        "                epochs_without_progress += 5\n",
        "                if epochs_without_progress > max_epochs_without_progress:\n",
        "                    print(\"Early stopping\")\n",
        "                    break"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tValidation accuracy: 94.260% \tLoss: 0.19163\n",
            "Epoch: 5 \tValidation accuracy: 96.320% \tLoss: 0.16395\n",
            "Epoch: 10 \tValidation accuracy: 97.160% \tLoss: 0.16883\n",
            "Epoch: 15 \tValidation accuracy: 97.100% \tLoss: 0.17678\n",
            "Epoch: 20 \tValidation accuracy: 97.160% \tLoss: 0.28826\n",
            "Epoch: 25 \tValidation accuracy: 96.820% \tLoss: 0.31844\n",
            "Epoch: 30 \tValidation accuracy: 96.340% \tLoss: 0.38536\n",
            "Epoch: 35 \tValidation accuracy: 96.200% \tLoss: 0.31970\n",
            "Epoch: 40 \tValidation accuracy: 97.060% \tLoss: 0.30107\n",
            "Epoch: 45 \tValidation accuracy: 96.840% \tLoss: 0.33455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VHwiuOsaZlki",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.remove(checkpoint_epoch_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QSSnCuNGZlki",
        "colab_type": "code",
        "outputId": "c87ef209-fa6c-4882-89a1-590a147b2f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, final_model_path)\n",
        "    accuracy_val = accuracy.eval(feed_dict={X: X_test, y: y_test})"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_deep_mnist_model1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JYEgII9wZlkx",
        "colab_type": "code",
        "outputId": "7ddce396-5257-49a5-ac97-807c5102cd31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "accuracy_val"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "R47RnPZ_Zlkx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def reset_graph():\n",
        "    tf.reset_default_graph()\n",
        "    \n",
        "reset_graph ()\n",
        "\n",
        "learning_rate = 0.01\n",
        "batch_size = 1000\n",
        "\n",
        "n_neuron_layer_1 = 300\n",
        "n_neuron_layer_2 = 100\n",
        "n_output = 10\n",
        "n_input = 28*28\n",
        "\n",
        "epoch_max = 1000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype(np.float32).reshape(-1, 28*28)\n",
        "X_test = X_test.astype(np.float32).reshape(-1, 28*28)\n",
        "y_test = y_test.astype(np.int32)\n",
        "y_train = y_train.astype(np.int32)\n",
        "\n",
        "def Shuffle_batch(X, y, batch_size):\n",
        "  rnd_idx = tf.random.permutation(len(X))\n",
        "  n_batch = len(X)//batch_size\n",
        "  for bach_idx in np.array_split(rnd_idx, n_batch):\n",
        "    X_batch, y_batch = X_batch [bach_idx], y_batch [batch_idx]\n",
        "  yield X_batch, y_batch\n",
        "  \n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_input), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "  hidden_1 = tf.layers.dense(X, n_neuron_layer_1, name = \"hidden_1\", activation = tf.nn.relu )\n",
        "  hidden_2 = tf.layers.dense(hidden_1, n_neuron_layer_2, name = \"hidden_2\", activation = tf.nn.relu )\n",
        "  logit = tf.layers.dense(hidden_2, n_output, name = \"logit\")\n",
        "  y_pred = tf.nn.relu(logit)\n",
        "\n",
        "with tf.name_scope(\"loss\"):\n",
        "  xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logit)\n",
        "            \n",
        "  loss = tf.reduce_mean(xentropy)\n",
        "  loss_summary = tf.summary.scalar ('log_loss', loss)\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "  optimizer = tf.train.AdamOptimizer (learning_rate=learning_rate)\n",
        "  trainig_op = optimizer.minimize(loss)\n",
        "               \n",
        "  \n",
        "with tf.name_scope(\"eval\"):\n",
        "  correct = tf.nn.in_top_k(logit, y, 1)\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        " # accuracy_summary = tf.summary.scalar('accuracy', correct)\n",
        "   \n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "check_point_path = \n",
        "check_poin_epoch_path = \n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  if os.path.isfile(check_point_epoch_path):\n",
        "    open(checkpoint_epoch_path, \"rb\")\n",
        "    with read(checkpoint_epoch_path, \"rb\") as f:\n",
        "      epoch_start = int(f.read)\n",
        "      saver.restore(sess, check_point_path)\n",
        "  else epoch_start = 0\n",
        "  \n",
        "  for epoch_n in range(epoch_start, epoch_max):\n",
        "    for X_batch, y_batch in shuffle_batch(X_train, y_train, bach_size):\n",
        "      sess.run(traning_op, feet_dict={X:X_batch, y:y_batch})\n",
        "    i_loss, i_loss_summary, i_accuracy, i_accuracy_summary = sess.run([loss, loss_summary, accuracy, accuracy_summary], feet_dict{X:X_test:y_test})\n",
        "    if epoch_n % 5 == 0:\n",
        "      print(\"Epoch:\", epoch_n, \"loss:\", i_loss, \"accuracy:\", i_accuracy)\n",
        "      saver.save(sess, check_point_path)\n",
        "      with open(checkpoint_epoch_path, \"wb\") as op:\n",
        "        ap.write(n_epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_KXxHcEybhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "478f3118-cef2-4a28-9578-79fbc6665099"
      },
      "cell_type": "code",
      "source": [
        "accuracy.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "OBaxgbcAjMZy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e54b2e9-68cf-4fa7-9dfa-ca47a638fd90"
      },
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}