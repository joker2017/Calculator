{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mobilenet Base Class.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joker2017/Calculator/blob/master/Mobilenet_Base_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_mPlJriXfz0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S1BpIwwHi4CZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aGMyiiffd54-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\"\"\"Mobilenet Base Class.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import collections\n",
        "import contextlib\n",
        "import copy\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "\n",
        "@slim.add_arg_scope\n",
        "def apply_activation(x, name=None, activation_fn=None):\n",
        "  return activation_fn(x, name=name) if activation_fn else x\n",
        "\n",
        "\n",
        "def _fixed_padding(inputs, kernel_size, rate=1):\n",
        "'''\n",
        "Дополняет ввод по пространственным измерениям независимо от размера ввода.\n",
        "\n",
        "Дополняет ввод таким образом, чтобы, если он использовался в свертке с 'VALID' padding, выход будет иметь такие же размеры, \n",
        "как если бы использовался незаполненный вход в свертке с 'SAME' padding.\n",
        "\n",
        "Args:\n",
        "   inputs: A tensor of size [batch, height_in, width_in, channels].\n",
        "   kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n",
        "   rate: целое число, скорость для свертывания\n",
        "Returns:\n",
        "   output: A tensor of size [batch, height_out, width_out, channels] with the input, либо нетронутым (if kernel_size == 1) либо с дополнением (if kernel_size > 1).\n",
        "'''\n",
        "  kernel_size_effective = [kernel_size[0] + (kernel_size[0] - 1) * (rate - 1),\n",
        "                           kernel_size[0] + (kernel_size[0] - 1) * (rate - 1)]\n",
        "  pad_total = [kernel_size_effective[0] - 1, kernel_size_effective[1] - 1]\n",
        "  pad_beg = [pad_total[0] // 2, pad_total[1] // 2]\n",
        "  pad_end = [pad_total[0] - pad_beg[0], pad_total[1] - pad_beg[1]]\n",
        "  padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg[0], pad_end[0]],\n",
        "                                  [pad_beg[1], pad_end[1]], [0, 0]])\n",
        "  return padded_inputs\n",
        "\n",
        "\n",
        "# название - сделать делимым\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "  if min_value is None:\n",
        "    min_value = divisor\n",
        "  new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "  #Убедитесь, что округление вниз не опускается более чем на 10%.\n",
        "  if new_v < 0.9 * v:\n",
        "    new_v += divisor\n",
        "  return new_v\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def _set_arg_scope_defaults(defaults):\n",
        "'''\n",
        "Устанавливает значения по умолчанию для arg scope для всех элементов, присутствующих в значениях по умолчанию.\n",
        "\n",
        "Args:\n",
        "  defaults: dictionary/list of pairs, containing a mapping from function to a dictionary of default args.\n",
        "  \n",
        "Yields:\n",
        "  context manager в котором установлены все значения по умолчанию.\n",
        "'''\n",
        "  if hasattr(defaults, 'items'):\n",
        "    items = list(defaults.items())\n",
        "  else:\n",
        "    items = defaults\n",
        "  if not items:\n",
        "    yield\n",
        "  else:\n",
        "    func, default_arg = items[0]\n",
        "    with slim.arg_scope(func, **default_arg):\n",
        "      with _set_arg_scope_defaults(items[1:]):\n",
        "        yield\n",
        "\n",
        "\n",
        "@slim.add_arg_scope\n",
        "def depth_multiplier(output_params,\n",
        "                     multiplier,\n",
        "                     divisible_by=8,\n",
        "                     min_depth=8,\n",
        "                     **unused_kwargs):\n",
        "  if 'num_outputs' not in output_params:\n",
        "    return\n",
        "  d = output_params['num_outputs']\n",
        "  output_params['num_outputs'] = _make_divisible(d * multiplier, divisible_by,\n",
        "                                                 min_depth)\n",
        "\n",
        "\n",
        "_Op = collections.namedtuple('Op', ['op', 'params', 'multiplier_func'])\n",
        "\n",
        "\n",
        "def op(opfunc, **params):\n",
        "  multiplier = params.pop('multiplier_transorm', depth_multiplier)\n",
        "  return _Op(opfunc, params=params, multiplier_func=multiplier)\n",
        "\n",
        "\n",
        "class NoOpScope(object):\n",
        "  \"\"\"No-op context manager.\"\"\"\n",
        "\n",
        "  def __enter__(self):\n",
        "    return None\n",
        "\n",
        "  def __exit__(self, exc_type, exc_value, traceback):\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def safe_arg_scope(funcs, **kwargs):\n",
        "\"\"\"Returns `slim.arg_scope` with all None arguments removed.\n",
        "\n",
        "  Arguments:\n",
        "    funcs: Functions to pass to `arg_scope`.\n",
        "    **kwargs: Arguments для передачи в `arg_scope`.\n",
        "\n",
        "  Returns:\n",
        "    arg_scope or No-op context manager.\n",
        "\n",
        "Примечание: может быть полезно, если значение None следует интерпретировать как «не перезаписывать» это значение параметра \".\n",
        "\"\"\"\n",
        "  filtered_args = {name: value for name, value in kwargs.items()\n",
        "                   if value is not None}\n",
        "  if filtered_args:\n",
        "    return slim.arg_scope(funcs, **filtered_args)\n",
        "  else:\n",
        "    return NoOpScope()\n",
        "\n",
        "\n",
        "@slim.add_arg_scope\n",
        "def mobilenet_base(  # pylint: disable=invalid-name\n",
        "    inputs,\n",
        "    conv_defs,\n",
        "    multiplier=1.0,\n",
        "    final_endpoint=None,\n",
        "    output_stride=None,\n",
        "    use_explicit_padding=False,\n",
        "    scope=None,\n",
        "    is_training=False):\n",
        "  \"\"\"Mobilenet base network.\n",
        "\n",
        "  Создает сеть от input до заданной конечной endpoint. По умолчанию сеть построена в режиме вывода. \n",
        "  Создать сеть в режиме тренировки используйте:\n",
        "  \n",
        "  with slim.arg_scope(mobilenet.training_scope()):\n",
        "     logits, endpoints = mobilenet_base(...)\n",
        "            \n",
        "   Args:\n",
        "     inputs: тензор формы [batch_size, height, width, channels].\n",
        "     conv_defs: список op(...) слоев, определяющих архитектуру сети.\n",
        "     multiplier: множитель с плавающей запятой для глубины (количество каналов)для всех операций свертки. \n",
        "        Значение должно быть больше нуля. Типичный будет использоваться для установки этого значения в (0, 1),\n",
        "        чтобы уменьшить количество параметры или стоимость расчета модели.\n",
        "     final_endpoint: имя последнего слоя, для досрочного завершения для сетей на основе V1: последний уровень - \"layer_14\", для V2: \"layer_20\"\n",
        "     output_stride: целое число, которое указывает запрошенное отношение ввода к выходное пространственное разрешение. \n",
        "        Если не None, то мы вызываем зловещую сверткуесли необходимо, чтобы сеть не уменьшала пространственное разрешение карты активации. \n",
        "        Допустимые значения: 1 или любое четное число, кроме нуль. Типичные значения: 8 (точный полностью сверточный режим), \n",
        "        16(быстрый полностью сверточный режим) и 32 (режим классификации).\n",
        "\n",
        "   ПРИМЕЧАНИЕ - output_stride опирается на все последующие операторы для поддержки расширенных операторов через параметр «rate».\n",
        "   Это может потребовать переноса неконвенционных операторов для правильной работы.\n",
        "\n",
        "    use_explicit_padding: Используйте заполнение 'VALID' для сверток, но вводите входные данные таким образом, чтобы выходные размеры\n",
        "        были такими же, как если бы использовалось заполнение 'SAME'. \n",
        "    scope: необязательная переменная область действия. \n",
        "    is_training: как настроить batch_norm и другие операции. Примечание: большую часть времени это не нужно устанавливать напрямую. \n",
        "        Вместо этого используйте mobilenet.training_scope () для настройки обучения. Этот параметр здесь только для обратной совместимости. \n",
        "        Безопасно установить его в значение, соответствующее training_scope (is_training = ...). Также безопасно явно установить его в False,\n",
        "        даже если для external training_scope установлено значение обучения. (Сеть будет построена в режиме вывода).\n",
        "        Если для этого параметра задано значение None, параметр arg_scope для параметра slim_batch_norm is_training не добавляется.\n",
        "\n",
        "  Returns:\n",
        "    tensor_out: output tensor.\n",
        "    end_points: набор активаций для внешнего использования, например, summaries or losses.\n",
        "  Raises:\n",
        "    ValueError: depth_multiplier <= 0, or the target output_stride is not\n",
        "                allowed.\n",
        "  \"\"\"\n",
        "  if multiplier <= 0:\n",
        "    raise ValueError('multiplier is not greater than zero.')\n",
        "\n",
        "  # Set conv defs defaults and overrides.\n",
        "  conv_defs_defaults = conv_defs.get('defaults', {})\n",
        "  conv_defs_overrides = conv_defs.get('overrides', {})\n",
        "  if use_explicit_padding:\n",
        "    conv_defs_overrides = copy.deepcopy(conv_defs_overrides)\n",
        "    conv_defs_overrides[\n",
        "        (slim.conv2d, slim.separable_conv2d)] = {'padding': 'VALID'}\n",
        "\n",
        "  if output_stride is not None:\n",
        "    if output_stride == 0 or (output_stride > 1 and output_stride % 2):\n",
        "      raise ValueError('Output stride must be None, 1 or a multiple of 2.')\n",
        "\n",
        "  # a) Set the tensorflow scope\n",
        "  # b) set padding to default: note we might consider removing this\n",
        "  # since it is also set by mobilenet_scope\n",
        "  # c) set all defaults\n",
        "  # d) set all extra overrides.\n",
        "  with _scope_all(scope, default_scope='Mobilenet'), \\\n",
        "      safe_arg_scope([slim.batch_norm], is_training=is_training), \\\n",
        "      _set_arg_scope_defaults(conv_defs_defaults), \\\n",
        "      _set_arg_scope_defaults(conv_defs_overrides):\n",
        "    #Переменная current_stride отслеживает ход вывода активаций, \n",
        "    #то есть текущий продукт свертки продвигается к текущему сетевому уровню. \n",
        "    #Это позволяет нам вызывать атральную свертку всякий раз, когда применение \n",
        "    #следующей свертки приведет к тому, что у активаций будет выходной шаг больше, чем целевой output_stride.\n",
        "    current_stride = 1\n",
        "\n",
        "    # The atrous convolution rate parameter.\n",
        "    rate = 1\n",
        "\n",
        "    net = inputs\n",
        "    # Вставьте параметры по умолчанию перед базовой областью, которая включает\n",
        "    # любые пользовательские переопределения, установленные в mobilenet.\n",
        "    end_points = {}\n",
        "    scopes = {}\n",
        "    for i, opdef in enumerate(conv_defs['spec']):\n",
        "      params = dict(opdef.params)\n",
        "      opdef.multiplier_func(params, multiplier)\n",
        "      stride = params.get('stride', 1)\n",
        "      if output_stride is not None and current_stride == output_stride:\n",
        "    # Если мы достигли цели output_stride, то нам нужно использовать \n",
        "    # atrous convolution с шагом = 1 и умножить скорость сердцебиения на \n",
        "    # шаг текущего юнита для использования в последующих слоях.\n",
        "        layer_stride = 1\n",
        "        layer_rate = rate\n",
        "        rate *= stride\n",
        "      else:\n",
        "        layer_stride = stride\n",
        "        layer_rate = 1\n",
        "        current_stride *= stride\n",
        "      # Update params.\n",
        "      params['stride'] = layer_stride\n",
        "      # Only insert rate to params if rate > 1.\n",
        "      if layer_rate > 1:\n",
        "        params['rate'] = layer_rate\n",
        "      # Set padding\n",
        "      if use_explicit_padding:\n",
        "        if 'kernel_size' in params:\n",
        "          net = _fixed_padding(net, params['kernel_size'], layer_rate)\n",
        "        else:\n",
        "          params['use_explicit_padding'] = True\n",
        "\n",
        "      end_point = 'layer_%d' % (i + 1)\n",
        "      try:\n",
        "        net = opdef.op(net, **params)\n",
        "      except Exception:\n",
        "        print('Failed to create op %i: %r params: %r' % (i, opdef, params))\n",
        "        raise\n",
        "      end_points[end_point] = net\n",
        "      scope = os.path.dirname(net.name)\n",
        "      scopes[scope] = end_point\n",
        "      if final_endpoint is not None and end_point == final_endpoint:\n",
        "        break\n",
        "\n",
        "    # Add all tensors that end with 'output' to\n",
        "    # endpoints\n",
        "    for t in net.graph.get_operations():\n",
        "      scope = os.path.dirname(t.name)\n",
        "      bn = os.path.basename(t.name)\n",
        "      if scope in scopes and t.name.endswith('output'):\n",
        "        end_points[scopes[scope] + '/' + bn] = t.outputs[0]\n",
        "    return net, end_points\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def _scope_all(scope, default_scope=None):\n",
        "  with tf.variable_scope(scope, default_name=default_scope) as s,\\\n",
        "       tf.name_scope(s.original_name_scope):\n",
        "    yield s\n",
        "\n",
        "\n",
        "@slim.add_arg_scope\n",
        "def mobilenet(inputs,\n",
        "              num_classes=1001,\n",
        "              prediction_fn=slim.softmax,\n",
        "              reuse=None,\n",
        "              scope='Mobilenet',\n",
        "              base_only=False,\n",
        "              **mobilenet_args):\n",
        "  \"\"\"Mobilenet model for classification, supports both V1 and V2.\n",
        "\n",
        "Примечание: режим по умолчанию - логический вывод, используйте mobilenet.training_scope для создания обучающей сети.\n",
        "\n",
        "\n",
        "  Args:\n",
        "    inputs: a tensor of shape [batch_size, height, width, channels].\n",
        "    num_classes: количество предсказанных классов. Если 0 или Нет, слой logits опущен, \n",
        "      и вместо него возвращаются входные объекты для слоя logits (до выпадения).\n",
        "    prediction_fn: функция для получения прогнозов из логитов (по умолчанию softmax).\n",
        "    reuse: следует ли повторно использовать сеть и ее переменные. Для возможности повторного \n",
        "      использования 'scope' должна быть предоставлена.\n",
        "    scope: Optional variable_scope.\n",
        "    base_only: если True только создаст базу сети (без пула и без логитов)..\n",
        "    **mobilenet_args: passed to mobilenet_base verbatim.\n",
        "      - conv_defs: list of conv defs\n",
        "      - multiplier: множитель с плавающей запятой для глубины (количества каналов) для всех \n",
        "        операций свертки. Значение должно быть больше нуля. Обычно используется для установки \n",
        "        этого значения в (0, 1), чтобы уменьшить количество параметров или стоимость вычислений модели.\n",
        "      - output_stride: будет гарантировать, что последний слой имеет не более общего шага. \n",
        "      Если архитектура требует большего шага, чем предусмотрено (например, output_stride = 16, \n",
        "      но архитектура имеет 5 stride = 2 оператора), она заменит output_stride с дробными \n",
        "      сверткой, используя Atrous Convolutions.\n",
        "\n",
        "  Returns:\n",
        "    logits: the pre-softmax activations, a tensor of size\n",
        "      [batch_size, num_classes]\n",
        "    end_points: a dictionary from components of the network to the corresponding\n",
        "      activation tensor.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: Input rank is invalid.\n",
        "  \"\"\"\n",
        "  is_training = mobilenet_args.get('is_training', False)\n",
        "  input_shape = inputs.get_shape().as_list()\n",
        "  if len(input_shape) != 4:\n",
        "    raise ValueError('Expected rank 4 input, was: %d' % len(input_shape))\n",
        "\n",
        "  with tf.variable_scope(scope, 'Mobilenet', reuse=reuse) as scope:\n",
        "    inputs = tf.identity(inputs, 'input')\n",
        "    net, end_points = mobilenet_base(inputs, scope=scope, **mobilenet_args)\n",
        "    if base_only:\n",
        "      return net, end_points\n",
        "\n",
        "    net = tf.identity(net, name='embedding')\n",
        "\n",
        "    with tf.variable_scope('Logits'):\n",
        "      net = global_pool(net)\n",
        "      end_points['global_pool'] = net\n",
        "      if not num_classes:\n",
        "        return net, end_points\n",
        "      net = slim.dropout(net, scope='Dropout', is_training=is_training)\n",
        "      # 1 x 1 x num_classes\n",
        "      # Note: legacy scope name.\n",
        "      logits = slim.conv2d(\n",
        "          net,\n",
        "          num_classes, [1, 1],\n",
        "          activation_fn=None,\n",
        "          normalizer_fn=None,\n",
        "          biases_initializer=tf.zeros_initializer(),\n",
        "          scope='Conv2d_1c_1x1')\n",
        "\n",
        "      logits = tf.squeeze(logits, [1, 2])\n",
        "\n",
        "      logits = tf.identity(logits, name='output')\n",
        "    end_points['Logits'] = logits\n",
        "    if prediction_fn:\n",
        "      end_points['Predictions'] = prediction_fn(logits, 'Predictions')\n",
        "  return logits, end_points\n",
        "\n",
        "\n",
        "def global_pool(input_tensor, pool_op=tf.nn.avg_pool):\n",
        "  \"\"\"Применяет пул avg для вывода 1x1.\n",
        "\n",
        "   ПРИМЕЧАНИЕ. Эта функция функционально эквивалентна limit_mean, но имеет средний пул, который имеет лучшую поддержку для всего оборудования.\n",
        "\n",
        "   Args:\n",
        "     input_tensor: входной тензор\n",
        "     pool_op: объединение в пул (средний пул по умолчанию)\n",
        "   Возвращает:\n",
        "     тензор batch_size x 1 x 1 x глубина.\n",
        "  \"\"\"\n",
        "  shape = input_tensor.get_shape().as_list()\n",
        "  if shape[1] is None or shape[2] is None:\n",
        "    kernel_size = tf.convert_to_tensor(\n",
        "        [1, tf.shape(input_tensor)[1],\n",
        "         tf.shape(input_tensor)[2], 1])\n",
        "  else:\n",
        "    kernel_size = [1, shape[1], shape[2], 1]\n",
        "  output = pool_op(\n",
        "      input_tensor, ksize=kernel_size, strides=[1, 1, 1, 1], padding='VALID')\n",
        "  # Recover output shape, for unknown shape.\n",
        "  output.set_shape([None, 1, 1, None])\n",
        "  return output\n",
        "\n",
        "\n",
        "def training_scope(is_training=True,\n",
        "                   weight_decay=0.00004,\n",
        "                   stddev=0.09,\n",
        "                   dropout_keep_prob=0.8,\n",
        "                   bn_decay=0.997):\n",
        "  \"\"\"Определяет область обучения Mobilenet.\n",
        "\n",
        "  Usage:\n",
        "     with tf.contrib.slim.arg_scope(mobilenet.training_scope()):\n",
        "       logits, endpoints = mobilenet_v2.mobilenet(input_tensor)\n",
        "\n",
        "   # созданная сеть будет работоспособна с dropout/batch norm инициализирован соответствующим образом.\n",
        "  \n",
        "  Args:\n",
        "    is_training: если установлено значение False, это гарантирует, что все настройки будут \n",
        "    установлены в режим без обучения. Это может быть полезно для кода, который повторно \n",
        "    используется для обучения / оценки, но большую часть времени training_scope со значением\n",
        "    False не требуется. Если для этого параметра установлено значение None, параметры не \n",
        "    добавляются в batch_norm arg_scope.\n",
        "\n",
        "    weight_decay: Снижение веса использовать для регуляризации модели.\n",
        "    stddev: Стандартное отклонение для инициализации, если отрицательное значение использует xavier.\n",
        "    dropout_keep_prob: вероятность dropout (не установлена, если равна None).\n",
        "    bn_decay: затухание для скользящих средних batch norm (не устанавливается, если равно None).\n",
        "\n",
        "  Returns:\n",
        "    An argument scope to use via arg_scope.\n",
        "  \"\"\"\n",
        "# Примечание: не вводите параметры, которые могли бы изменить модель логического вывода здесь \n",
        "# (например, использовать ли смещение), вместо этого измените conv_def.\n",
        "  batch_norm_params = {\n",
        "      'decay': bn_decay,\n",
        "      'is_training': is_training\n",
        "  }\n",
        "  if stddev < 0:\n",
        "    weight_intitializer = slim.initializers.xavier_initializer()\n",
        "  else:\n",
        "    weight_intitializer = tf.truncated_normal_initializer(stddev=stddev)\n",
        "\n",
        "  # Установите weight_decay для весов в слоях Conv и FC.\n",
        "  with slim.arg_scope(\n",
        "      [slim.conv2d, slim.fully_connected, slim.separable_conv2d],\n",
        "      weights_initializer=weight_intitializer,\n",
        "      normalizer_fn=slim.batch_norm), \\\n",
        "      slim.arg_scope([mobilenet_base, mobilenet], is_training=is_training),\\\n",
        "      safe_arg_scope([slim.batch_norm], **batch_norm_params), \\\n",
        "      safe_arg_scope([slim.dropout], is_training=is_training,\n",
        "                     keep_prob=dropout_keep_prob), \\\n",
        "      slim.arg_scope([slim.conv2d], \\\n",
        "                     weights_regularizer=slim.l2_regularizer(weight_decay)), \\\n",
        "      slim.arg_scope([slim.separable_conv2d], weights_regularizer=None) as s:\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}