{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolution blocks for mobilenet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joker2017/Calculator/blob/master/Convolution_blocks_for_mobilenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7TvQjMDI-TKZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"Convolution blocks for mobilenet.\"\"\"\n",
        "import contextlib\n",
        "import functools\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "\n",
        "def _fixed_padding(inputs, kernel_size, rate=1):\n",
        "  \"\"\"Дополняет ввод по пространственным измерениям независимо от размера ввода.\n",
        "\n",
        "  Дополняет ввод так, что если бы он использовался в свертке с заполнением 'VALID',\n",
        "  выход имел бы те же размеры, как если бы незаполненный ввод использовался в свертке\n",
        "  с заполнением 'SAME'.\n",
        "\n",
        "  Args:\n",
        "    inputs: A tensor of size [batch, height_in, width_in, channels].\n",
        "    kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n",
        "    rate: An integer, rate for atrous convolution.\n",
        "\n",
        "  Returns:\n",
        "    output: A tensor of size [batch, height_out, width_out, channels] with the\n",
        "      input, either intact (if kernel_size == 1) or padded (if kernel_size > 1).\n",
        "  \"\"\"\n",
        "  kernel_size_effective = [kernel_size[0] + (kernel_size[0] - 1) * (rate - 1),\n",
        "                           kernel_size[0] + (kernel_size[0] - 1) * (rate - 1)]\n",
        "  pad_total = [kernel_size_effective[0] - 1, kernel_size_effective[1] - 1]\n",
        "  pad_beg = [pad_total[0] // 2, pad_total[1] // 2]\n",
        "  pad_end = [pad_total[0] - pad_beg[0], pad_total[1] - pad_beg[1]]\n",
        "  padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg[0], pad_end[0]],\n",
        "                                  [pad_beg[1], pad_end[1]], [0, 0]])\n",
        "  return padded_inputs\n",
        "\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "  if min_value is None:\n",
        "    min_value = divisor\n",
        "  new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "  # Make sure that round down does not go down by more than 10%.\n",
        "  if new_v < 0.9 * v:\n",
        "    new_v += divisor\n",
        "  return new_v\n",
        "\n",
        "\n",
        "def _split_divisible(num, num_ways, divisible_by=8):\n",
        "  \"\"\"Равномерно разбивает num, num_ways, поэтому каждый фрагмент кратен divisible_by.\"\"\"\n",
        "  assert num % divisible_by == 0\n",
        "  assert num / num_ways >= divisible_by\n",
        "  # Примечание: хотите округлить, мы корректируем каждый сплит в соответствии с итогом.\n",
        "  base = num // num_ways // divisible_by * divisible_by\n",
        "  result = []\n",
        "  accumulated = 0\n",
        "  for i in range(num_ways):\n",
        "    r = base\n",
        "    while accumulated + r < num * (i + 1) / num_ways:\n",
        "      r += divisible_by\n",
        "    result.append(r)\n",
        "    accumulated += r\n",
        "  assert accumulated == num\n",
        "  return result\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def _v1_compatible_scope_naming(scope):\n",
        "  if scope is None:  # Create uniqified separable blocks.\n",
        "    with tf.variable_scope(None, default_name='separable') as s, \\\n",
        "         tf.name_scope(s.original_name_scope):\n",
        "      yield ''\n",
        "  else:\n",
        "    # Мы используем scope_depthwise, scope_pointwise для совместимости с v1 ckpts, которые предоставляют пронумерованные области.\n",
        "    \n",
        "    scope += '_'\n",
        "    yield scope\n",
        "\n",
        "\n",
        "@slim.add_arg_scope\n",
        "def split_separable_conv2d(input_tensor,\n",
        "                           num_outputs,\n",
        "                           scope=None,\n",
        "                           normalizer_fn=None,\n",
        "                           stride=1,\n",
        "                           rate=1,\n",
        "                           endpoints=None,\n",
        "                           use_explicit_padding=False):\n",
        "  \"\"\"Separable mobilenet V1 style convolution.\n",
        "\n",
        "  Глубинная свертка, с нелинейностью по умолчанию,\n",
        "  с последующей глубокой сверткой 1x1. Это похоже на\n",
        "  slim.separable_conv2d, но отличается тем, что применяет пакет\n",
        "  нормализация и нелинейность по глубине. Это соответствует\n",
        "  основное здание Mobilenet Paper\n",
        "  (https://arxiv.org/abs/1704.04861)\n",
        "\n",
        "  Args:\n",
        "    input_tensor: input\n",
        "    num_outputs: количество выходов\n",
        "    scope: необязательное имя области. Обратите внимание, что при наличии он будет использовать \n",
        "    scope_depthwise для deptwhise и scope_pointwise для pointwise. \n",
        "    normalizer_fn: какую функцию нормализатора использовать для depthwise/pointwise\n",
        "    stride: stride\n",
        "    rate: output rate (также известный как скорость расширения)\n",
        "    endpoints: необязательно, если предоставлено, экспортирует дополнительные тензоры к нему.\n",
        "    use_explicit_padding: Используйте заполнение 'VALID' для сверток, но вводите входные \n",
        "    данные таким образом, чтобы выходные размеры были такими же, как если бы использовалось \n",
        "    заполнение 'SAME'.\n",
        "\n",
        "  Returns:\n",
        "    output tesnor\n",
        "  \"\"\"\n",
        "\n",
        "  with _v1_compatible_scope_naming(scope) as scope:\n",
        "    dw_scope = scope + 'depthwise'\n",
        "    endpoints = endpoints if endpoints is not None else {}\n",
        "    kernel_size = [3, 3]\n",
        "    padding = 'SAME'\n",
        "    if use_explicit_padding:\n",
        "      padding = 'VALID'\n",
        "      input_tensor = _fixed_padding(input_tensor, kernel_size, rate)\n",
        "    net = slim.separable_conv2d(\n",
        "        input_tensor,\n",
        "        None,\n",
        "        kernel_size,\n",
        "        depth_multiplier=1,\n",
        "        stride=stride,\n",
        "        rate=rate,\n",
        "        normalizer_fn=normalizer_fn,\n",
        "        padding=padding,\n",
        "        scope=dw_scope)\n",
        "\n",
        "    endpoints[dw_scope] = net\n",
        "\n",
        "    pw_scope = scope + 'pointwise'\n",
        "    net = slim.conv2d(\n",
        "        net,\n",
        "        num_outputs, [1, 1],\n",
        "        stride=1,\n",
        "        normalizer_fn=normalizer_fn,\n",
        "        scope=pw_scope)\n",
        "    endpoints[pw_scope] = net\n",
        "  return net\n",
        "\n",
        "\n",
        "def expand_input_by_factor(n, divisible_by=8):\n",
        "  return lambda num_inputs, **_: _make_divisible(num_inputs * n, divisible_by)\n",
        "\n",
        "\n",
        "@slim.add_arg_scope\n",
        "def expanded_conv(input_tensor,\n",
        "                  num_outputs,\n",
        "                  expansion_size=expand_input_by_factor(6),\n",
        "                  stride=1,\n",
        "                  rate=1,\n",
        "                  kernel_size=(3, 3),\n",
        "                  residual=True,\n",
        "                  normalizer_fn=None,\n",
        "                  project_activation_fn=tf.identity,\n",
        "                  split_projection=1,\n",
        "                  split_expansion=1,\n",
        "                  expansion_transform=None,\n",
        "                  depthwise_location='expansion',\n",
        "                  depthwise_channel_multiplier=1,\n",
        "                  endpoints=None,\n",
        "                  use_explicit_padding=False,\n",
        "                  padding='SAME',\n",
        "                  scope=None):\n",
        "  \"\"\"Depthwise Convolution Block with expansion.\n",
        "  Блок глубокой свертки с расширением.\n",
        "\n",
        "\n",
        "  Создает сложную свертку, которая имеет следующую структуру\n",
        "  расширение (1x1) -> depthwise (kernel_size) -> projection (1x1)\n",
        "\n",
        "  Args:\n",
        "    input_tensor: input\n",
        "    num_outputs: количество выходов в последнем слое.\n",
        "    expansion_size: Размер расширения может быть постоянным или вызываемым.\n",
        "    В последнем случае будет предоставлено num_inputs в качестве входных данных. Для прямой \n",
        "    совместимости он должен принимать произвольные аргументы ключевых слов. По умолчанию \n",
        "    будет расширять ввод в 6 раз.\n",
        "    stride: depthwise stride\n",
        "    rate: depthwise rate\n",
        "    kernel_size: depthwise kernel\n",
        "    residual: включить ли  residual connection(остаточную связь) между input и output.\n",
        "    normalizer_fn: batchnorm или иное\n",
        "    project_activation_fn: activation function for the project layer\n",
        "    split_projection: how many ways to split projection operator\n",
        "      (that is conv expansion->bottleneck)\n",
        "    split_expansion: how many ways to split expansion op\n",
        "      (that is conv bottleneck->expansion) ops will keep depth divisible\n",
        "      by this value.\n",
        "    expansion_transform: Необязательная функция, которая принимает расширение как один вход и возвращает вывод.\n",
        "    depthwise_location: куда поместить глубинные значения covnvolutions, поддерживаемые None, 'input', 'output', 'extension'\n",
        "    depthwise channel multiplier:\n",
        "    each input will replicated (with different filters)\n",
        "    that many times. So if input had c channels,\n",
        "    output will have c x depthwise_channel_multpilier.\n",
        "    endpoints: Необязательный словарь, в который помещаются промежуточные конечные точки. \n",
        "    Ключи \"extension_output\", \"deepwise_output\", \"projection_output\" и \n",
        "    \"extension_transform\" всегда заполняются, даже если соответствующие функции не вызываются.\n",
        "    use_explicit_padding: Используйте заполнение 'VALID' для сверток, но вводите входные \n",
        "    данные таким образом, чтобы выходные размеры были такими же, как если бы использовалось заполнение 'SAME'.\n",
        "    padding: Тип заполнения, если `use_explicit_padding` не установлен.\n",
        "    scope: optional scope.\n",
        "\n",
        "  Returns:\n",
        "    Tensor of depth num_outputs\n",
        "    Тензор глубины num_outputs\n",
        "\n",
        "  Raises:\n",
        "    TypeError: on inval\n",
        "  \"\"\"\n",
        "  with tf.variable_scope(scope, default_name='expanded_conv') as s, \\\n",
        "       tf.name_scope(s.original_name_scope):\n",
        "    prev_depth = input_tensor.get_shape().as_list()[3]\n",
        "    if  depthwise_location not in [None, 'input', 'output', 'expansion']:\n",
        "      raise TypeError('%r is unknown value for depthwise_location' %\n",
        "                      depthwise_location)\n",
        "    if use_explicit_padding:\n",
        "      if padding != 'SAME':\n",
        "        raise TypeError('`use_explicit_padding` should only be used with '\n",
        "                        '\"SAME\" padding.')\n",
        "      padding = 'VALID'\n",
        "    depthwise_func = functools.partial(\n",
        "        slim.separable_conv2d,\n",
        "        num_outputs=None,\n",
        "        kernel_size=kernel_size,\n",
        "        depth_multiplier=depthwise_channel_multiplier,\n",
        "        stride=stride,\n",
        "        rate=rate,\n",
        "        normalizer_fn=normalizer_fn,\n",
        "        padding=padding,\n",
        "        scope='depthwise')\n",
        "    # b1 -> b2 * r -> b2\n",
        "    #   i -> (o * r) (bottleneck) -> o\n",
        "    input_tensor = tf.identity(input_tensor, 'input')\n",
        "    net = input_tensor\n",
        "\n",
        "    if depthwise_location == 'input':\n",
        "      if use_explicit_padding:\n",
        "        net = _fixed_padding(net, kernel_size, rate)\n",
        "      net = depthwise_func(net, activation_fn=None)\n",
        "\n",
        "    if callable(expansion_size):\n",
        "      inner_size = expansion_size(num_inputs=prev_depth)\n",
        "    else:\n",
        "      inner_size = expansion_size\n",
        "\n",
        "    if inner_size > net.shape[3]:\n",
        "      net = split_conv(\n",
        "          net,\n",
        "          inner_size,\n",
        "          num_ways=split_expansion,\n",
        "          scope='expand',\n",
        "          stride=1,\n",
        "          normalizer_fn=normalizer_fn)\n",
        "      net = tf.identity(net, 'expansion_output')\n",
        "    if endpoints is not None:\n",
        "      endpoints['expansion_output'] = net\n",
        "\n",
        "    if depthwise_location == 'expansion':\n",
        "      if use_explicit_padding:\n",
        "        net = _fixed_padding(net, kernel_size, rate)\n",
        "      net = depthwise_func(net)\n",
        "\n",
        "    net = tf.identity(net, name='depthwise_output')\n",
        "    if endpoints is not None:\n",
        "      endpoints['depthwise_output'] = net\n",
        "    if expansion_transform:\n",
        "      net = expansion_transform(expansion_tensor=net, input_tensor=input_tensor)\n",
        "    #Обратите внимание, что в отличие от расширения, у нас всегда есть проекция для получения желаемого выходного размера.\n",
        "    net = split_conv(\n",
        "        net,\n",
        "        num_outputs,\n",
        "        num_ways=split_projection,\n",
        "        stride=1,\n",
        "        scope='project',\n",
        "        normalizer_fn=normalizer_fn,\n",
        "        activation_fn=project_activation_fn)\n",
        "    if endpoints is not None:\n",
        "      endpoints['projection_output'] = net\n",
        "    if depthwise_location == 'output':\n",
        "      if use_explicit_padding:\n",
        "        net = _fixed_padding(net, kernel_size, rate)\n",
        "      net = depthwise_func(net, activation_fn=None)\n",
        "\n",
        "    if callable(residual):  # custom residual/ таможенный остаток\n",
        "      net = residual(input_tensor=input_tensor, output_tensor=net)\n",
        "    elif (residual and\n",
        "          # проверка шага гарантирует, что мы не добавляем остатки, когда пространственные измерения отсутствуют\n",
        "          stride == 1 and\n",
        "          # Depth matches/Глубина совпадений\n",
        "          net.get_shape().as_list()[3] ==\n",
        "          input_tensor.get_shape().as_list()[3]):\n",
        "      net += input_tensor\n",
        "    return tf.identity(net, name='output')\n",
        "\n",
        "\n",
        "def split_conv(input_tensor,\n",
        "               num_outputs,\n",
        "               num_ways,\n",
        "               scope,\n",
        "               divisible_by=8,\n",
        "               **kwargs):\n",
        "  \"\"\"Creates a split convolution.\n",
        "  \n",
        "  Разбиение свертки разделяет вход и выход на блоки 'num_blocks' примерно одинакового размера \n",
        "  каждый и соединяет только $ i $ -ый вход с выходом $ i $.\n",
        "\n",
        "  Args:\n",
        "    input_tensor: input tensor\n",
        "    num_outputs: number of output filters\n",
        "    num_ways: num blocks to split by./количество блоков для разделения\n",
        "    scope: scope for all the operators.\n",
        "    divisible_by: make sure that every part is divisiable by this./убедитесь, что каждая часть делится этим.\n",
        "    **kwargs: will be passed directly into conv2d operator/будет передано непосредственно в conv2d оператор\n",
        "  Returns:\n",
        "    tensor\n",
        "  \"\"\"\n",
        "  b = input_tensor.get_shape().as_list()[3]\n",
        "\n",
        "  if num_ways == 1 or min(b // num_ways,\n",
        "                          num_outputs // num_ways) < divisible_by:\n",
        "    # Don't do any splitting if we end up with less than 8 filters\n",
        "    # on either side.\n",
        "    return slim.conv2d(input_tensor, num_outputs, [1, 1], scope=scope, **kwargs)\n",
        "\n",
        "  outs = []\n",
        "  input_splits = _split_divisible(b, num_ways, divisible_by=divisible_by)\n",
        "  output_splits = _split_divisible(\n",
        "      num_outputs, num_ways, divisible_by=divisible_by)\n",
        "  inputs = tf.split(input_tensor, input_splits, axis=3, name='split_' + scope)\n",
        "  base = scope\n",
        "  for i, (input_tensor, out_size) in enumerate(zip(inputs, output_splits)):\n",
        "    scope = base + '_part_%d' % (i,)\n",
        "    n = slim.conv2d(input_tensor, out_size, [1, 1], scope=scope, **kwargs)\n",
        "    n = tf.identity(n, scope + '_output')\n",
        "    outs.append(n)\n",
        "  return tf.concat(outs, 3, name=scope + '_concat')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}