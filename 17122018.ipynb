{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17122018.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joker2017/Calculator/blob/master/17122018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Jwe1UXvnqIK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "ee6fc346-4783-47c5-8677-eebcada7088e"
      },
      "cell_type": "code",
      "source": [
        "#готовим данные\n",
        "import sys\n",
        "import tarfile\n",
        "import os\n",
        "from six.moves import urllib\n",
        "\n",
        "FLOWERS_URL = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "FLOWERS_PATH = os.path.join(\"datasets\", \"flowers\")\n",
        "\n",
        "\n",
        "#Загрузите последнюю предварительную модель Inception v3: контрольная точка доступна по адресу https://github.com/tensorflow/models/tree/master/research/slim . \n",
        "#писок имен классов доступен по адресу https://goo.gl/brXRtZ , но вы должны сначала вставить «background» класс.\n",
        "\n",
        "import sys\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "\n",
        "TF_MODELS_URL = \"http://download.tensorflow.org/models\"\n",
        "INCEPTION_V3_URL = TF_MODELS_URL + \"/inception_v3_2016_08_28.tar.gz\"\n",
        "INCEPTION_PATH = os.path.join(\"datasets\", \"inception\")\n",
        "INCEPTION_V3_CHECKPOINT_PATH = os.path.join(INCEPTION_PATH, \"inception_v3.ckpt\")\n",
        "\n",
        "def download_progress(count, block_size, total_size):\n",
        "    percent = count * block_size * 100 // total_size\n",
        "    sys.stdout.write(\"\\rDownloading: {}%\".format(percent))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "def fetch_pretrained_inception_v3(url=INCEPTION_V3_URL, path=INCEPTION_PATH):\n",
        "    if os.path.exists(INCEPTION_V3_CHECKPOINT_PATH):\n",
        "        return\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    tgz_path = os.path.join(path, \"inception_v3.tgz\")\n",
        "    urllib.request.urlretrieve(url, tgz_path, reporthook=download_progress)\n",
        "    inception_tgz = tarfile.open(tgz_path)\n",
        "    inception_tgz.extractall(path=path)\n",
        "    inception_tgz.close()\n",
        "    os.remove(tgz_path)\n",
        "\n",
        "fetch_pretrained_inception_v3()   \n",
        "import re\n",
        "\n",
        "CLASS_NAME_REGEX = re.compile(r\"^n\\d+\\s+(.*)\\s*$\", re.M | re.U)\n",
        "\n",
        "def load_class_names():\n",
        "    with open(os.path.join(\"datasets\", \"inception\", \"imagenet_class_names.txt\"), \"rb\") as f:\n",
        "        content = f.read().decode(\"utf-8\")\n",
        "        return CLASS_NAME_REGEX.findall(content)\n",
        "      \n",
        "class_names = [\"background\"] + load_class_names()     \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "    \n",
        "    \n",
        "def fetch_flowers(url=FLOWERS_URL, path=FLOWERS_PATH):\n",
        "    if os.path.exists(FLOWERS_PATH):\n",
        "        return\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    tgz_path = os.path.join(path, \"flower_photos.tgz\")\n",
        "    urllib.request.urlretrieve(url, tgz_path, reporthook=download_progress)\n",
        "    flowers_tgz = tarfile.open(tgz_path)\n",
        "    flowers_tgz.extractall(path=path)\n",
        "    flowers_tgz.close()\n",
        "    os.remove(tgz_path)\n",
        "    \n",
        "fetch_flowers()\n",
        "\n",
        "\n",
        "#Каждый подкаталог flower_photos каталога содержит все изображения данного класса. Давайте получим список классов:\n",
        "flowers_root_path = os.path.join(FLOWERS_PATH, \"flower_photos\")\n",
        "flower_classes = sorted([dirname for dirname in os.listdir(flowers_root_path)\n",
        "                  if os.path.isdir(os.path.join(flowers_root_path, dirname))])\n",
        "#flower_classes\n",
        "\n",
        "\n",
        "#Давайте получим список всех путей файлов изображений для каждого класса:\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "image_paths = defaultdict(list)\n",
        "\n",
        "for flower_class in flower_classes:\n",
        "    image_dir = os.path.join(flowers_root_path, flower_class)\n",
        "    for filepath in os.listdir(image_dir):\n",
        "        if filepath.endswith(\".jpg\"):\n",
        "            image_paths[flower_class].append(os.path.join(image_dir, filepath))\n",
        "            \n",
        "            \n",
        "#Давайте сортируем пути изображения, чтобы заставить этот ноутбук вести себя последовательно на нескольких запусках:\n",
        "\n",
        "for paths in image_paths.values():\n",
        "    paths.sort() \n",
        "\n",
        "    \n",
        "#Для получения дополнительных функций манипуляции с изображениями, таких как вращения, проверьте документацию SciPy или эту приятную страницу .\n",
        "\n",
        "from scipy.misc import imresize\n",
        "\n",
        "def prepare_image(image, target_width = 299, target_height = 299, max_zoom = 0.2):\n",
        "    \"\"\"Zooms and crops the image randomly for data augmentation.\"\"\"\n",
        "\n",
        "    # First, let's find the largest bounding box with the target size ratio that fits within the image\n",
        "    height = image.shape[0]\n",
        "    width = image.shape[1]\n",
        "    image_ratio = width / height\n",
        "    target_image_ratio = target_width / target_height\n",
        "    crop_vertically = image_ratio < target_image_ratio\n",
        "    crop_width = width if crop_vertically else int(height * target_image_ratio)\n",
        "    crop_height = int(width / target_image_ratio) if crop_vertically else height\n",
        "        \n",
        "    # Now let's shrink this bounding box by a random factor (dividing the dimensions by a random number\n",
        "    # between 1.0 and 1.0 + `max_zoom`.\n",
        "    resize_factor = np.random.rand() * max_zoom + 1.0\n",
        "    crop_width = int(crop_width / resize_factor)\n",
        "    crop_height = int(crop_height / resize_factor)\n",
        "    \n",
        "    # Next, we can select a random location on the image for this bounding box.\n",
        "    x0 = np.random.randint(0, width - crop_width)\n",
        "    y0 = np.random.randint(0, height - crop_height)\n",
        "    x1 = x0 + crop_width\n",
        "    y1 = y0 + crop_height\n",
        "    \n",
        "    # Let's crop the image using the random bounding box we built.\n",
        "    image = image[y0:y1, x0:x1]\n",
        "\n",
        "    # Let's also flip the image horizontally with 50% probability:\n",
        "    if np.random.rand() < 0.5:\n",
        "        image = np.fliplr(image)\n",
        "\n",
        "    # Now, let's resize the image to the target dimensions.\n",
        "    image = imresize(image, (target_width, target_height))\n",
        "    \n",
        "    # Finally, let's ensure that the colors are represented as\n",
        "    # 32-bit floats ranging from 0.0 to 1.0 (for now):\n",
        "    return image.astype(np.float32) / 255\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  #снова получить начальный график v3. На этот раз воспользуемся trainingзаполнителем\n",
        "  \n",
        "from tensorflow.contrib.slim.nets import inception\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=[None, height, width, channels], name=\"X\")\n",
        "training = tf.placeholder_with_default(False, shape=[])\n",
        "with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
        "    logits, end_points = inception.inception_v3(X, num_classes=1001, is_training=training)\n",
        "\n",
        "inception_saver = tf.train.Saver()\n",
        "\n",
        "\n",
        "#изучить входные данные выходного уровня:\n",
        "# logits.op.inputs[0].op.inputs[0]  или end_points\n",
        "end_points[\"PreLogits\"]\n",
        "\n",
        "#отказаться от 2-го и 3-го измерений с помощью tf.squeeze() функции\n",
        "prelogits = tf.squeeze(end_points[\"PreLogits\"], axis=[1, 2])\n",
        "\n",
        "#добавить окончательный полностью подключенный слой поверх этого слоя:\n",
        "  \n",
        "n_outputs = len(flower_classes)\n",
        "\n",
        "with tf.name_scope(\"new_output_layer\"):\n",
        "    flower_logits = tf.layers.dense(prelogits, n_outputs, name=\"flower_logits\")\n",
        "    Y_proba = tf.nn.softmax(flower_logits, name=\"Y_proba\")\n",
        "    \n",
        "#Добавляемстандвартные вещи\n",
        "\n",
        "y = tf.placeholder(tf.int32, shape=[None])\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=flower_logits, labels=y)\n",
        "    loss = tf.reduce_mean(xentropy)\n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    flower_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"flower_logits\")\n",
        "    training_op = optimizer.minimize(loss, var_list=flower_vars)\n",
        "\n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(flower_logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "with tf.name_scope(\"init_and_save\"):\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver() \n",
        "    \n",
        "    \n",
        "#Разделите свой набор данных на тренировочный набор и тестовый набор. Обучите модель тренировочному набору и оцените его на тестовом наборе.\n",
        "\n",
        "#Во-первых, мы хотим представить классы как int, а не строки:\n",
        "\n",
        "flower_class_ids = {flower_class: index for index, flower_class in enumerate(flower_classes)}\n",
        "#flower_class_ids\n",
        "\n",
        "#Будет проще перетасовать набор данных, если мы представим его как список пар filepath / class:\n",
        "\n",
        "flower_paths_and_classes = []\n",
        "for flower_class, paths in image_paths.items():\n",
        "    for path in paths:\n",
        "        flower_paths_and_classes.append((path, flower_class_ids[flower_class]))\n",
        "        \n",
        "#Затем давайте перетасовать набор данных и разделим его на обучающий набор и тестовый набор:\n",
        "\n",
        "test_ratio = 0.2\n",
        "train_size = int(len(flower_paths_and_classes) * (1 - test_ratio))\n",
        "\n",
        "np.random.shuffle(flower_paths_and_classes)\n",
        "\n",
        "flower_paths_and_classes_train = flower_paths_and_classes[:train_size]\n",
        "flower_paths_and_classes_test = flower_paths_and_classes[train_size:]\n",
        "\n",
        "# предварительной обработки набора тестов, а также для создания партий во время обучения. Для простоты мы будем использовать реализацию NumPy / SciPy:\n",
        "from random import sample\n",
        "\n",
        "def prepare_batch(flower_paths_and_classes, batch_size):\n",
        "    batch_paths_and_classes = sample(flower_paths_and_classes, batch_size)\n",
        "    images = [mpimg.imread(path)[:, :, :channels] for path, labels in batch_paths_and_classes]\n",
        "    prepared_images = [prepare_image(image) for image in images]\n",
        "    X_batch = 2 * np.stack(prepared_images) - 1 # Inception expects colors ranging from -1 to 1\n",
        "    y_batch = np.array([labels for path, labels in batch_paths_and_classes], dtype=np.int32)\n",
        "    return X_batch, y_batch\n",
        "  \n",
        "X_batch, y_batch = prepare_batch(flower_paths_and_classes_train, batch_size=4)\n",
        "\n",
        "#Теперь давайте использовать эту функцию для подготовки тестового набора:\n",
        "\n",
        "X_test, y_test = prepare_batch(flower_paths_and_classes_test, batch_size=len(flower_paths_and_classes_test))\n",
        "\n",
        "#И теперь мы готовы обучить сеть (или, точнее, только что добавленный выходной слой, поскольку все остальные слои заморожены). Имейте в виду, что это может занять (очень) долгое время.\n",
        "\n",
        "#раннняя остановка\n",
        "def get_model_params():\n",
        "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
        "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
        "\n",
        "def restore_model_params(model_params):\n",
        "    gvar_names = list(model_params.keys())\n",
        "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
        "                  for gvar_name in gvar_names}\n",
        "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
        "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
        "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "n_epochs = 1000\n",
        "batch_size = 50\n",
        "\n",
        "best_loss_val = np.infty\n",
        "check_interval = 500\n",
        "checks_since_last_progress = 0\n",
        "max_checks_without_progress = 20\n",
        "best_model_params = None \n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
        "            if iteration % check_interval == 0:\n",
        "                loss_val = loss.eval(feed_dict={X: mnist.validation.images,\n",
        "                                                y: mnist.validation.labels})\n",
        "                if loss_val < best_loss_val:\n",
        "                    best_loss_val = loss_val\n",
        "                    checks_since_last_progress = 0\n",
        "                    best_model_params = get_model_params()\n",
        "                else:\n",
        "                    checks_since_last_progress += 1\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,\n",
        "                                           y: mnist.validation.labels})\n",
        "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
        "                  epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
        "        if checks_since_last_progress > max_checks_without_progress:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "    if best_model_params:\n",
        "        restore_model_params(best_model_params)\n",
        "    acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
        "                                        y: mnist.test.labels})\n",
        "    print(\"Final accuracy on test set:\", acc_test)\n",
        "    save_path = saver.save(sess, \"./my_mnist_model\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: 100%"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-95b7e333a04a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCLASS_NAME_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"background\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mload_class_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-95b7e333a04a>\u001b[0m in \u001b[0;36mload_class_names\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_class_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inception\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"imagenet_class_names.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCLASS_NAME_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/inception/imagenet_class_names.txt'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uXuKWQRjqK3R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kb1z-kCBqLA8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KZx31Biwqb3Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ранняя остановка"
      ]
    },
    {
      "metadata": {
        "id": "BiYr1gVzdlGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model_params():\n",
        "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
        "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
        "\n",
        "def restore_model_params(model_params):\n",
        "    gvar_names = list(model_params.keys())\n",
        "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
        "                  for gvar_name in gvar_names}\n",
        "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
        "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
        "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BV44UIhhdlGM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 1000\n",
        "batch_size = 50\n",
        "\n",
        "best_loss_val = np.infty\n",
        "check_interval = 500\n",
        "checks_since_last_progress = 0\n",
        "max_checks_without_progress = 20\n",
        "best_model_params = None \n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
        "            if iteration % check_interval == 0:\n",
        "                loss_val = loss.eval(feed_dict={X: mnist.validation.images,\n",
        "                                                y: mnist.validation.labels})\n",
        "                if loss_val < best_loss_val:\n",
        "                    best_loss_val = loss_val\n",
        "                    checks_since_last_progress = 0\n",
        "                    best_model_params = get_model_params()\n",
        "                else:\n",
        "                    checks_since_last_progress += 1\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,\n",
        "                                           y: mnist.validation.labels})\n",
        "        print(\"Epoch {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
        "                  epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
        "        if checks_since_last_progress > max_checks_without_progress:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "    if best_model_params:\n",
        "        restore_model_params(best_model_params)\n",
        "    acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
        "                                        y: mnist.test.labels})\n",
        "    print(\"Final accuracy on test set:\", acc_test)\n",
        "    save_path = saver.save(sess, \"./my_mnist_model\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}