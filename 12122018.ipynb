{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joker2017/Calculator/blob/master/12122018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "onS64To2TAih",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "learning_rate = 0.01\n",
        "batch_size = 1000\n",
        "n_layers_1 = 300\n",
        "n_layers_2 = 200\n",
        "n_layers_3 = 100\n",
        "n_layers_4 = 50\n",
        "epoch_max = 100\n",
        "output = 10\n",
        "\n",
        "\n",
        "X = tf.placeholder (tf.float32, shape=(None, 28*28), name=\"X\")\n",
        "y = tf.placeholder (tf.int32, shape=(None), name=\"y\")\n",
        "training = tf.placeholder_with_default(False, shape=(None), name=\"training\")\n",
        "batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
        "\n",
        "def shuffle_batch (X, y, batch_size):\n",
        "  rnd_id = np.randome.permutation(len(X))\n",
        "  batch_rnd = len(X)//batch_size\n",
        "  for batch_n in np.array_split(rnd_id, batch_rnd):\n",
        "    X_batch, y_batch = X[batch_n], y[batch_n]\n",
        "  yield X_batch, y_batch\n",
        "  \n",
        "(X_train, y_train), (X_valid, y_valid) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype(np.float32).reshape(-1, 28*28)\n",
        "X_valid = X_valid.astype(np.float32).reshape(-1, 28*28)\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_valid = y_valid.astype(np.int32)\n",
        "X_train, X_valid = X_train[:5000], X_train[5000:]\n",
        "y_train, y_valid = y_train[:5000], y_train[5000:]\n",
        "\n",
        "with tf.name_scope(\"DNN\"):\n",
        "  \n",
        "  hidden_1 = tf.layers.dense(X, n_layers_1, activation=tf.nn.elu, name=\"hidden_1\")\n",
        "  \n",
        "  hidden_2 = tf.layers.dense(hidden_1, n_layers_2, name=\"hidden_2\")\n",
        "  hidden_2_bn = batch_norm_layer(hidden_2, name=\"hidden_2_bn\")\n",
        "  Hidden_2_bn_act = tf.nn.relu(hidden_2_bn, name=\"Hidden_2_bn_act\")\n",
        "  \n",
        "  hidden_3 = tf.layers.dense(Hidden_2_bn_act, n_layers_3, name=\"hidden_3\")\n",
        "  hidden_3_bn = batch_norm_layer(hidden_3, name=\"hidden_3_bn\")\n",
        "  Hidden_3_bn_act = tf.nn.relu(hidden_3_bn, name=\"Hidden_3_bn_act\")\n",
        "  \n",
        "  hidden_4 = tf.layers.dense(Hidden_3_bn_act, n_layers_4, name=\"hidden_4\")\n",
        "  hidden_4_bn = batch_norm_layer(hidden_4, name=\"hidden_4_bn\")\n",
        "  Hidden_4_bn_act = tf.nn.relu(hidden_4_bn, name=\"Hidden_4_bn_act\") \n",
        "  \n",
        "  logits_without_bn = tf.layers.dense(Hidden_4_bn_act, output, name=\"logits_without_bn\")\n",
        "  logits = batch_norm_layer(logits_without_bn, name=\"logits\")\n",
        "  \n",
        "with tf.name_scope(\"loss\"):\n",
        "  xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits=logits)\n",
        "  loss = tf.reduce_mean(xentropy)\n",
        "  loss_sum = tf.summary.scalar('loss_sum', loss)\n",
        "  \n",
        "with tf.name_scope(\"train\"):\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "  training_op = optimizer.minimize(loss)\n",
        "  \n",
        "with tf.name_scope(\"eval\"):\n",
        "  prediction = tf.nn.in_top_k(logits, y, 1)\n",
        "  accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
        "  accuracy_sum = tf.summary.scalar('accuracy_sum', accuracy)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}